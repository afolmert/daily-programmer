 
r/dailyprogrammer
log insign upsign in
Reddit Feeds

  • popular
  • all
  • 

Sign up and stay connected to your favorite communities.

sign uplog in
 
r/

dailyprogrammer

Posts
55
Posted by
u/nint22
1 24 years ago

[05/13/13] Challenge #125 [Easy] Word Analytics

 (Easy): Word Analytics

You're a newly hired engineer for a brand-new company that's building a "killer
Word-like application". You've been specifically assigned to implement a tool
that gives the user some details on common word usage, letter usage, and some
other analytics for a given document! More specifically, you must read a given
text file (no special formatting, just a plain ASCII text file) and print off
the following details:

 1. Number of words

 2. Number of letters

 3. Number of symbols (any non-letter and non-digit character, excluding white
    spaces)

 4. Top three most common words (you may count "small words", such as "it" or
    "the")

 5. Top three most common letters

 6. Most common first word of a paragraph (paragraph being defined as a block
    of text with an empty line above it) (Optional bonus)

 7. Number of words only used once (Optional bonus)

 8. All letters not used in the document (Optional bonus)

Please note that your tool does not have to be case sensitive, meaning the word
"Hello" is the same as "hello" and "HELLO".

Author: nint22

Formal Inputs & Outputs

Input Description

As an argument to your program on the command line, you will be given a text
file location (such as "C:\Users\nint22\Document.txt" on Windows or "/Users/
nint22/Document.txt" on any other sane file system). This file may be empty,
but will be guaranteed well-formed (all valid ASCII characters). You can assume
that line endings will follow the UNIX-style new-line ending (unlike the
Windows carriage-return & new-line format ).

Output Description

For each analytic feature, you must print the results in a special string
format. Simply you will print off 6 to 8 sentences with the following format:

"A words", where A is the number of words in the given document
"B letters", where B is the number of letters in the given document
"C symbols", where C is the number of non-letter and non-digit character, excluding white spaces, in the document
"Top three most common words: D, E, F", where D, E, and F are the top three most common words
"Top three most common letters: G, H, I", where G, H, and I are the top three most common letters
"J is the most common first word of all paragraphs", where J is the most common word at the start of all paragraphs in the document (paragraph being defined as a block of text with an empty line above it) (*Optional bonus*)
"Words only used once: K", where K is a comma-delimited list of all words only used once (*Optional bonus*)
"Letters not used in the document: L", where L is a comma-delimited list of all alphabetic characters not in the document (*Optional bonus*)

If there are certain lines that have no answers (such as the situation in which
a given document has no paragraph structures), simply do not print that line of
text. In this example, I've just generated some random Lorem Ipsum text.

Sample Inputs & Outputs

Sample Input

*Note that "MyDocument.txt" is just a Lorem Ipsum text file that conforms to
this challenge's well-formed text-file definition.

./MyApplication /Users/nint22/MyDocument.txt

Sample Output

Note that we do not print the "most common first word in paragraphs" in this
example, nor do we print the last two bonus features:

265 words
1812 letters
59 symbols
Top three most common words: "Eu", "In", "Dolor"
Top three most common letters: 'I', 'E', 'S'

102 comments
share
91% Upvoted
Sort by
best
 
best
 
top
 
new
 
controversial
 
old
 
q&a
nint22
1 2Original Poster18 points·4 years ago

Heads up to new programmers: though the spec (specification) here is long, the
challenge is quite easy :-) If anyone needs help, remember that we're full of
awesome peers here, so don't be afraid to post some initial questions or
thoughts!

share
Save
terminatortg
9 points·4 years ago

Can you make your Lorem Ipsum file available for download?

share
Save
NUNTIUMNECAVI
12 points·4 years ago

Here's a 30-paragraph one.

share
Save
specialk16
3 points·4 years ago

I'm using this one however it would've been nice to have one official file to
compare results against.

(and yeah, 17 days left but I've kept this tab opened that long so I could do
this as soon as I had a chance lol).

share
Save
nint22
1 2Original Poster3 points·4 years ago

It was randomly generated, and already lost, but you make a great point. When I
get home, I'll host the file on my server and update the sample input / output.

share
Save
GhostNULL
3 points·4 years ago

I actually did something like this a while ago, it wasn't all of it...but I am
sure I can extend it:P

share
Save
MrHotShotBanker
8 points·4 years ago

I seem to be in a catch 22 here.

I really want to improve my C++ skills by doing some of these challenges but
find them too difficult to understand because of my beginners/novice
understanding of C++. Any [very easy] challenges by any chance?

share
Save
nint22
1 2Original Poster12 points·4 years ago

Good questions! The reality is that putting a correct difficulty label is super
hard: it's subjective to begin win, and we only use 3 difficulty types for the
sake of keeping things organized and not get overwhelmed by a ton of different
labels.

That being said, browse around some of the older [Easy] challenges as some are
exceptionally easy, while others are right in the middle of Easy and
Intermediate. If you still have problems with past [Easy] challenges, maybe
consider doing a small side project first to really get comfortable with C++:
write a little text editor like Nano, or make a tool to track your grocery
spending. Tiny things like that are easy to do and are, more importantly, a
great way to learn a language.

If this is your first language, maybe consider grabbing an appropriate book. I
really enjoyed the "Learn C++ in 21 Days" series; it's free (Google around for
it) and a great way to learn to code for non-programmers. It's a little dry,
but better than the cartoonified programmer books.

share
Save
MrHotShotBanker
3 points·4 years ago

awesome, thanks for the great advice nint! will do more browsing!

share
Save
xanderstrike
1 07 points·4 years ago·edited 4 years ago

Late to the party as always. Ruby < 25 lines with all bonuses but most common
first word.

        file = ARGV.first
        puts "Analyzing #{file}"
        word_count = 0
        word_hash = Hash.new(0)
        letter_count = 0
        letter_hash = Hash.new(0)
        symbols = 0
        File.open(file, 'r') do |f|
                while line = f.gets
                        symbols += line.gsub(/\w|\s/, '').size
                        words = line.downcase.split.map{|x| x.gsub(/\W/,"")}
                        word_count += words.size
                        words.each {|w| word_hash[w] += 1}
                        line.downcase.gsub(/\W|\d/, '').each_char {|l| letter_hash[l] += 1; letter_count += 1}
                end
        end
        word_hash = word_hash.sort_by {|key,val| val}

        puts "Words: #{word_count}\nLetters: #{letter_count}\nSymbols: #{symbols}"
        puts "Most Used Words: #{word_hash.reverse[0..4].join(" ")}"
        puts "Most Used Letters: #{letter_hash.sort_by {|key,val| val}.reverse[0..4].join(" ")}"
        puts "Unused letters: #{([*('a'..'z')] + letter_hash.keys - ([*('a'..'z')] & letter_hash.keys)).join(', ')}"
        puts "Words Used Once: #{word_hash.map {|key,value| key if value == 1}.compact.join(', ')}"

Input: http://filer.case.edu/dts8/thelastq.htm

Output:

Analyzing test-document.txt
Words: 4668
Letters: 20494
Symbols: 1190
Most Used Words: the 261 of 142 and 123 a 107 to 103
Most Used Letters: e 2468 t 1888 a 1747 o 1495 n 1467
Unused letters:
Words Used Once: <list of 682 words>

Edit: Ran it again on all 4.2mb of the King James Bible. Takes about 9 seconds
on my machine.

Analyzing kjv.txt
Words: 824146
Letters: 3239443
Symbols: 157406
Most Used Words: the 64203 and 51764 of 34789 to 13660 that 12927
Most Used Letters: e 412232 t 317744 h 282678 a 275727 o 243185
Unused letters:
Words Used Once: <list of 5842 words>

share
Save
juliolingus
3 points·4 years ago

I think someone wins the game.

share
Save
d347hm4n
5 points·4 years ago

My attempt in c#

    using System;
    using System.Collections.Generic;
    using System.Linq;
    using System.Text;
    using System.IO;
    using System.Text.RegularExpressions;

namespace WordAnalytics
{
    class Program
    {
        static void Main(string[] args)
        {
            if (args.Length != 1) //Supply path to a file
                return;

            string filename = args[0];

            if (!File.Exists(filename)) //File must exist
                return;

            string[] file = File.ReadAllLines(filename);


            int totalWords = 1;
            int totalLetters = 1;
            int symbols = 1;
            Dictionary<string, int> commonWords = new Dictionary<string, int>();
            Dictionary<char, int> commonLetters = new Dictionary<char, int>();

            foreach (string line in file)
            {
                totalWords += (line.Split(' ')).Length;
                totalLetters += (Regex.Replace(line, @"[^A-Za-z0-9\s]", "",RegexOptions.Compiled)).Length; //anything not alphanumeric or whitespace
                symbols += (Regex.Replace(line, @"[A-Za-z0-9\s]", "", RegexOptions.Compiled)).Length; //anything that is alphanumeric or whitespace

                string[] words = Regex.Replace(line, @"[^A-Za-z0-9\s]", "", RegexOptions.Compiled).Split(' ');
                foreach (string word in words)
                {
                    if (!commonWords.ContainsKey(word))
                        commonWords.Add(word,1);
                    else
                        commonWords[word] += 1;
                }

                string letters = Regex.Replace(line, @"[^A-Za-z0-9]", "", RegexOptions.Compiled);
                foreach (char letter in letters)
                {
                    if(!commonLetters.ContainsKey(letter))
                        commonLetters.Add(letter,1);
                    else
                        commonLetters[letter] += 1;
                }
            }

            //Display number of words in the file
            Console.WriteLine(totalWords.ToString() + " words in the file.");
            //Display number of letters
            Console.WriteLine(totalLetters.ToString() + " letters in the file.");
            //Display number of symbols
            Console.WriteLine(symbols.ToString() + " symbols in the file.");
            //3 most common words
            List<KeyValuePair<string, int>> wordList = commonWords.ToList();
            wordList.Sort((firstPair, nextPair) =>
                {
                    return firstPair.Value.CompareTo(nextPair.Value);
                });

            Console.WriteLine(wordList[wordList.Count - 2].Key + ", " + wordList[wordList.Count - 3].Key + " and " + wordList[wordList.Count - 4].Key + " are the most common words.");

            //3 most common letters
            List<KeyValuePair<char, int>> charList = commonLetters.ToList();
            charList.Sort((firstPair, nextPair) =>
                {
                    return firstPair.Value.CompareTo(nextPair.Value);
                });

            Console.WriteLine(charList[charList.Count - 2].Key + ", " + charList[charList.Count - 3].Key + " and " + charList[charList.Count - 4].Key + " are the most common letters.");

            //Common first word of paragraph
            //TODO:


            //Number of words only used once
            string soloWords = string.Empty;
            foreach (KeyValuePair<string,int> solo in wordList)
                if (solo.Value == 1)
                    soloWords += solo.Key + ", ";

            Console.WriteLine(soloWords.Substring(0, soloWords.Length - 2) + " are words only used once");

            //All leters not used in the document
            //TODO:

            Console.ReadKey();
        }
    }
}

output is as follows:

3090 words in the file.
19602 letters in the file.
625 symbols in the file.
sit, amet and et are the most common words.
i, u and s are the most common letters.
taciti, sociosqu, ad, potenti, Class, aptent, litora, nostra, inceptos, himenaeo
s, torquent, conubia are words only used once

I used the supplied lorem dipsum file.

Comments welcomed!

share
Save
Coder_d00d
1 35 points·4 years ago

I liked how you used C#. I have not used it before but it reads a lot like C++
and Objective C.

Your total variables (symbols, totalWords, totalLetters) are initialized to 1
-- maybe they need to be 0 - I come up with 624 symbols - you got 625 for
example.

Your regular expressions might need changing.

For letters you are matching [^A-Za-z0-9\s]

You are counting whitespace \s as letters. You have like 3000 more letters than
others. Your word count seems to be different from others too.

Although the description for the challenge didn't say I would say any word is
[A-Za-z]+ and any letter is just [A-Za-z] -- I would ignore digits.

I am not very good with C# but from what I saw on some searches on the Regex
class I really liked the Matches() method in that it returns a collection of
matches. And then you can just take the count of those.

So something along the lines of....

string wordPattern = @"[A-Za-z]+";

string letterPattern = @"[A-Za-z]";

string symbolPattern = @"[!-/:-@[-'{-~]"; //these are ranges of what i called
symbol chars on ascii table

Regex findWords = new Regex(wordPattern);

Regex findLetters = new Regex(letterPattern);

Regex findSymbols = new Regex(symbolPattern);

(Then in your foreach (string line in file) loop )

totalWords += (findWords.Matches(line)).Count;

totalLetters += (findLetters.Matches(line)).Count;

symbols += (findSymbols.Matches(line)).Count;

In your dictionary adds you might need to make sure every letter is the same
case. So like if you have the word Ipsum and then later you get ipsum -- is it
incrementing 1 entry of "ipsum" or is it creating 2 word counts one for "Ipsum"
and "ipsum"?

overall cool use of C#

share
Save
fecal_brunch
5 points·4 years ago·edited 4 years ago

First time submitting to this subreddit. Thought I'd practise my C# LINQ
skills. Certainly not the most efficient way to approach the problem, but it
was fun to write.

I didn't bother with the bonus marks because it's 2am and I have work tomorrow.
:-) Next time!

Also I got different results to u/NUNTIUMNECAVI for the most common words.

using System;
using System.IO;
using System.Linq;
using System.Text.RegularExpressions;

public class Easy
{
  public static void Main( string[] args )
  {
    var streamReader = new StreamReader( args[0] );
    var fileContent = streamReader.ReadToEnd();

    var words = Regex.Matches( fileContent, @"\b\w+\b" ).Cast<Match>()
      .Select( m => m.Value.ToLower() );

    var wordCount = words.Count();

    var letterCount = words.Aggregate( 0, (total, next) => total + next.Length );

    var symbolCount = fileContent
      .Where( c => !char.IsLetterOrDigit( c ) && !char.IsWhiteSpace( c ) )
      .Count();

    var mostCommonWords = words
      .GroupBy( w => w )
      .Select( g => new { Word = g.Key, Count = g.Count() } )
      .OrderBy( i => i.Count )
      .Reverse()
      .Take( 3 )
      .Select( i => i.Word );

    var mostCommonLetters = words
      .SelectMany( w => w )
      .GroupBy( w => w )
      .Select( g => new { Letter = g.Key, Count = g.Count() } )
      .OrderBy( i => i.Count )
      .Reverse()
      .Take( 3 )
      .Select( i => i.Letter );

    Console.Write( string.Format(
        "{0} Words\n{1} Letters\n{2} Symbols\nTop three most common words: {3}\nTop three most common letters: {4}\n",
        wordCount, letterCount, symbolCount,
        string.Join( ", ", mostCommonWords.Select( w => string.Format( "\"{0}\"", Capitalize( w ) ) ).ToArray() ),
        string.Join( ", ", mostCommonLetters.Select( l => string.Format( "'{0}'", char.ToUpper( l ) ) ).ToArray() )
      )
    );
  }

  static string Capitalize( string word )
  {
    var chars = word.ToCharArray();
    chars[0] = char.ToUpper( word[0] );
    return new string( chars );
  }
}

share
Save
chekt
9 points·4 years ago

This is my solution in ANSI C. I still haven't decided which C idioms I want to
follow, and so my code is a bit inconsistent.

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <ctype.h>

#define OFFSET 97
#define MAX_WORD_LENGTH 500


typedef struct word_list {
        char* word;
        int count;
        struct word_list *next;
} w_list;

void print_unused_letters(char *s) {
        int i;
        int alph[26] = {0};
        int len = strlen(s);

        for (i = 0; i < len; i++) {
                char tmp = s[i] - OFFSET;

                if (tmp >= 0 && tmp < 26)
                        alph[tmp]++;
        }
        int first = 1;
        for (i = 0; i < 26; i++) {
                if (alph[i] == 0)  {
                        if (! first)
                                printf(", ");
                        printf("%c", i+OFFSET);
                        first = 0;
                }
        }
        return;
}
void top_letters(char *s, char *letters) {
        int i;
        int alph[26] = {0};
        int len = strlen(s);

        for (i = 0; i < len; i++) {
                char tmp = s[i] - OFFSET;

                if (tmp >= 0 && tmp < 26)
                        alph[tmp]++;
        }
        int letter_c[3] = {0};

        for (i = 0; i < 26; i++) {
                int j;
                for (j = 0; j < 3; j++) {
                        if (alph[i] > letter_c[j]) {
                                int k;
                                for (k = 2; k > j; k--) {
                                        letters[k] = letters[k-1];
                                        letter_c[k] = letter_c[k-1];
                                }
                                letters[j] = i+OFFSET;
                                letter_c[j] = alph[i];
                                break;
                        }
                }
        }
        return;
}

int num_words(char* s) {
        int wc = 0;
        int i = 0;
        int in_word = 0;
        while (s[i] != '\0') {
                int is_letter = (s[i] - OFFSET >= 0 && s[i] - OFFSET < 26);
                if (in_word && !is_letter) {
                        in_word = 0;
                        wc++;
                } else if (!in_word && is_letter) {
                        in_word = 1;
                }
                i++;
        }
        return wc;
}

int num_letters(char* s) {
        int lc = 0;
        int i = 0;
        while (s[i] != '\0') {
                int is_letter = (s[i] - OFFSET >= 0 && s[i] - OFFSET < 26);
                if (is_letter)
                        lc++;
                i++;
        }
        return lc;
}

int num_symbols(char* s) {
        int sc = 0;
        int i = 0;
        while (s[i] != '\0') {
                int is_symbol = (s[i] > 32 && s[i] < 97) ||
                        (s[i] > 122 && s[i] < 127);
                if (is_symbol) {
                        sc++;
                }
                i++;
        }
        return sc;
}

void increment_list(w_list *head, char *word) {
        if (head->word == NULL) {
                head->word = word;
                head->count = 1;
        } else {
                int found = 0;
                w_list *list = head;
                w_list *prev_n = NULL;
                while (list != NULL) {
                        if (strcmp(list->word, word) == 0) {
                                list->count++;
                                found = 1;
                                break;
                        } else {
                                prev_n = list;
                                list = list->next;
                        }
                }
                if (! found) {
                        w_list *nw = malloc(sizeof(w_list));
                        nw->word = word;
                        nw->count = 1;
                        nw->next = NULL;
                        prev_n->next = nw;
                }
        }
}

void *populate_word_list(char *s, w_list *words, int para) {
        words->word = NULL;
        words->next = NULL;

        char buffer[MAX_WORD_LENGTH];
        int ib = 0;
        int i = 0;
        int in_word = 0;
        int in_para = 1;
        while (s[i] != '\0') {
                int is_letter = (s[i] - OFFSET >= 0 && s[i] - OFFSET < 26);
                if (! para || in_para) {
                        if (in_word && !is_letter) {
                                in_word = 0;
                                buffer[ib] = '\0';
                                char *str = malloc((ib + 2) * sizeof(char));
                                strcpy(str, buffer);
                                increment_list(words, str);
                                in_para = 0;
                        } else if (!in_word && is_letter) {
                                in_word = 1;
                                ib = 0;
                                buffer[ib] = s[i];
                        } else if (is_letter) {
                                buffer[ib] = s[i];
                        }
                        ib++;
                } else if (s[i] == '\n') {
                        in_para = 1;
                }
                i++;
        }
        return;
}


void top_words(w_list *words, char **t_words) {
        int i, j;
        int c_words[3] = {0};

        while (words != NULL) {
                for (i = 0; i < 3; i++) {
                        if (words->count > c_words[i]) {
                                for (j = 2; j > i; j--) {
                                        c_words[j] = c_words[j-1];
                                        t_words[j] = t_words[j-1];
                                }
                                c_words[i] = words->count;
                                t_words[i] = words->word;
                                break;
                        }
                }
                words = words->next;
        }
        return;
}

char *com_fst_word(w_list *words) {
        char *t = NULL;
        int count = 0;

        while (words != NULL) {
                if (words->count > count) {
                        count = words->count;
                        t = words->word;
                }
                words = words->next;
        }
        return t;
}

w_list *words_only_once(w_list *words) {
        w_list *left = NULL;
        w_list *head = NULL;

        while (words != NULL) {
                if (words->count > 1) {
                        if (left != NULL) {
                                left->next = words->next;
                        }
                } else {
                        if (left == NULL) {
                                head = words;
                        }
                        left = words;
                }
                words = words->next;
        }
        return head;
}




int main(int argc, char** argv) {
        if (argc < 2) {
                printf("error: no argument");
                return 1;
        }
        FILE *f = fopen(argv[1], "r");
        if (f == NULL) {
                printf("error: file not found");
                return 2;
        }
        fseek(f, 0, SEEK_END);
        int fsize = ftell(f);
        rewind(f);
        char * s = malloc (sizeof(char) * fsize);
        fread (s, sizeof(char), fsize, f);

        int i = 0;
        while (s[i] != '\0') {
                s[i] = tolower(s[i]);
                i++;
        }

        int wc = num_words(s);
        printf("%d words\n", wc);

        int lc = num_letters(s);
        printf("%d letters\n", lc);

        int sc = num_symbols(s);
        printf("%d symbols\n", sc);

        w_list *words = malloc(sizeof(w_list));
        populate_word_list(s, words, 0);
        char *t_w[3];
        top_words(words, t_w);
        printf("Top three most common words: %s, %s, %s\n",
                        t_w[0], t_w[1], t_w[2]);

        char ls[3];
        top_letters(s, ls);
        printf("Top three most common letters are: %c, %c, %c\n",
                        ls[0], ls[1], ls[2]);

        w_list *fst_paras = malloc(sizeof(w_list));
        populate_word_list(s, fst_paras, 1);
        char *top_para = com_fst_word(fst_paras);
        printf("%s is the most common first word of all paragraphs\n",
                        top_para);

        w_list *once = words_only_once(words);
        printf("Words only used once: ");
        int first = 1;
        while (once != NULL) {
                if (! first) {
                        printf(", ");
                }
                printf("%s", once->word);
                first = 0;
                once = once->next;
        }
        printf("\n");

        printf("Letters not used in the document: ");
        print_unused_letters(s);
        printf("\n");

        return 0;
}

output:

3002 words
16571 letters
624 symbols
Top three most common words: ut, in, sed
Top three most common letters are: e, i, u
vestibulum is the most common first word of all paragraphs
Words only used once: potenti, class, aptent, taciti, sociosqu, ad, litora, torquent, conubia, nostra, inceptos, himenaeos
Letters not used in the document: k, w, x, y, z

share
Save
[deleted]
1 point·4 years ago

very very impressive

share
Save
m_farce
5 points·4 years ago

Java. First submission, no bonus. Any advice/criticism would be appreciated as
I just started learning Java recently.

public static void main(String args[]) {

        File file = new File(args[0]);

        try {

                Scanner myScan = new Scanner(file);
                ArrayList<String> wordList = new ArrayList<String>();
                Map<String, Integer> wordDupes = new HashMap<String, Integer>();
                Map<String, Integer> letterDupes = new HashMap<String, Integer>();

                int letterCount = 0;
                int symbolCount = 0;

                while (myScan.hasNext()) {

                        String tempString = myScan.next().toLowerCase();
                        wordList.add(tempString.toLowerCase());
                        char lineChars[] = tempString.toCharArray();

                        tempString = tempString.replaceAll("\\p{Punct}", "");
                        if (wordDupes.containsKey(tempString)) {

                                wordDupes.put(tempString, wordDupes.get(tempString) + 1);
                        } else {

                                wordDupes.put(tempString, 1);
                        }

                        for (int i = 0; i < lineChars.length; i++) {

                                if (Character.isLetterOrDigit(lineChars[i])) {
                                        letterCount++;
                                        tempString = Character.toString(lineChars[i]);

                                        if (letterDupes.containsKey(tempString)) {

                                                letterDupes.put(tempString, letterDupes.get(tempString) + 1);
                                        } else {

                                                letterDupes.put(tempString, 1);
                                        }

                                } else {
                                        symbolCount++;
                                }
                        }
                }

                String topWords = getTopThree(wordDupes);
                String topLetters = getTopThree(letterDupes);

                System.out.println("The text file has " + wordList.size() + " words.");
                System.out.println("The text file has " + letterCount + " letters.");
                System.out.println("The text file has " + symbolCount + " symbols.");
                System.out.println("The three most common words are: " + topWords);
                System.out.println("The three most common letters are: " + topLetters);

                myScan.close();
        } catch (FileNotFoundException e) {

                System.out.println(e);
        }
}

public static String getTopThree(Map<String, Integer> dupes) {
        int wordCount[] = { 0, 0, 0 };
        List<String> commonCount = Arrays.asList("", "", "");

        for (String s : dupes.keySet()) {

                if (dupes.get(s) >= wordCount[2]) {

                        commonCount.set(0, commonCount.get(1));
                        wordCount[0] = wordCount[1];
                        commonCount.set(1, commonCount.get(2));
                        wordCount[1] = wordCount[2];
                        commonCount.set(2, s);
                        wordCount[2] = dupes.get(s);
                } else if (dupes.get(s) >= wordCount[1]) {

                        commonCount.set(0, commonCount.get(1));
                        wordCount[0] = wordCount[1];
                        commonCount.set(1, s);
                        wordCount[1] = dupes.get(s);
                } else if (dupes.get(s) >= wordCount[0]) {

                        commonCount.set(0, s);
                        wordCount[0] = dupes.get(s);
                }
        }

        return commonCount.get(2) + " (" + wordCount[2] + "), " + commonCount.get(1) + " (" + wordCount[1] + "), " + commonCount.get(0)+ " (" + wordCount[0] + ")";
}

Output using 30_paragraph_lorem_ipsum.txt from pastebin.

The text file has 3002 words.
The text file has 16571 letters.
The text file has 624 symbols.
The three most common words are: ut (56), sed (53), in (53)
The three most common letters are: e (1921), i (1703), u (1524)

share
Save
is_58_6
1 point·4 years ago

Late to the party, but here's my own Java implementation:

package challenge125;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.util.HashMap;
import java.util.Map;
import java.util.regex.Matcher;
import java.util.regex.Pattern;

public class WordAnalytics {

        private static final Pattern WORD_PATTERN = Pattern.compile("\\w+");
        private static final Pattern LETTER_PATTERN = Pattern.compile("\\w");
        private static final Pattern SYMBOL_PATTERN = Pattern.compile("[^\\w\\s]");

        private String text;

        public WordAnalytics(File file) throws IOException {
                text = readTextFile(file);
        }

        private String readTextFile(File file) throws IOException {
                StringBuilder sb = new StringBuilder();
                BufferedReader reader = new BufferedReader(new FileReader(file));
                char[] buffer = new char[1024];
                int charsRead;
                while ((charsRead = reader.read(buffer)) != -1) {
                        String readData = String.valueOf(buffer, 0, charsRead);
                        sb.append(readData);
                }
                reader.close();
                return sb.toString();
        }

        public int getWords() {
                return countOccurences(WORD_PATTERN);
        }

        public int getLetters() {
                return countOccurences(LETTER_PATTERN);
        }

        public int getSymbols() {
                return countOccurences(SYMBOL_PATTERN);
        }

        private int countOccurences(Pattern pattern) {
                Matcher matcher = pattern.matcher(text);
                int occurences = 0;
                while (matcher.find()) {
                        occurences++;
                }
                return occurences;
        }

        public String[] getTopWords() {
                return getTopOccurences(WORD_PATTERN);
        }

        public String[] getTopLetters() {
                return getTopOccurences(LETTER_PATTERN);
        }

        private String[] getTopOccurences(Pattern pattern) {
                Matcher matcher = pattern.matcher(text);
                Map<String, Integer> counts = new HashMap<String, Integer>();
                while (matcher.find()) {
                        String occurence = matcher.group().toLowerCase();
                        int count = counts.containsKey(occurence) ? counts.get(occurence) + 1 : 1;
                        counts.put(occurence, count);
                }
                String[] topOccurences = new String[3];
                for (int i = 0; i < 3; i++) {
                        String[] occurences = counts.keySet().toArray(new String[0]);
                        String topOccurence = occurences[0];
                        for (String occurence : occurences) {
                                if (counts.get(occurence) > counts.get(topOccurence)) {
                                        topOccurence = occurence;
                                }
                        }
                        topOccurences[i] = topOccurence;
                        counts.remove(topOccurence);
                }
                return topOccurences;
        }

        public String getAnalysis() {
                StringBuilder sb = new StringBuilder();
                sb.append(getWords()).append(" words\n");
                sb.append(getLetters()).append(" letters\n");
                sb.append(getSymbols()).append(" symbols\n");
                String[] topWords = getTopWords();
                sb.append("Top three most common words: ")
                        .append(topWords[0]).append(", ")
                        .append(topWords[1]).append(", ")
                        .append(topWords[2]).append("\n");
                String[] topLetters = getTopLetters();
                sb.append("Top three most common letters: ")
                        .append(topLetters[0]).append(", ")
                        .append(topLetters[1]).append(", ")
                        .append(topLetters[2]).append("\n");
                return sb.toString();
        }

        public static void main(String[] args) throws Exception {
                String pathname = args[0];
                File file = new File(pathname);
                WordAnalytics analytics = new WordAnalytics(file);
                System.out.print(analytics.getAnalysis());
        }

}

Result:

3002 words
16571 letters
624 symbols
Top three most common words: ut, in, sed
Top three most common letters: e, i, u

share
Save
Captain_Hillman
2 points·4 years ago

Also super-late, but here's my Java implementation hastily done during lunch
(107 lines in all)...

public static void main(String[] args) {
    long start = new Date().getTime();

    HashMap<String, Integer> wordCounts = new HashMap<>();
    HashMap<String, Integer> letterCounts = new HashMap<>();
    ArrayList<Character> chars = new ArrayList<>(Arrays.asList('a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',
            'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'));

    Scanner scanner = new Scanner("");
    try {
        scanner = new Scanner(new File(args[0]));
    } catch(FileNotFoundException fnfExp) {
        System.out.println("oops...");
        System.exit(-1);
    }

    int wordCount = 0;
    int letterCount = 0;
    int symbolCount = 0;

    while(scanner.hasNext()) {
        String word = scanner.next().trim().toLowerCase();
        if(word.isEmpty()) {
            continue;
        }
        wordCount++;

        for(int j = 0; j < word.length(); j++) {
            if(!Character.isLetterOrDigit(word.charAt(j))) {
                symbolCount++;
            } else {
                letterCount++;
            }

            if(chars.contains(word.charAt(j))) {
                chars.remove(new Character(word.charAt(j)));
            }

            String letter = Character.toString(word.charAt(j));
            if(!letterCounts.containsKey(letter)) {
                letterCounts.put(letter, 1);
            } else {
                letterCounts.put(letter, letterCounts.get(letter) + 1);
            }
        }

        String puncFreeWord = word.replaceAll("[^A-Za-z]", "");
        if(!wordCounts.containsKey(puncFreeWord)) {
            wordCounts.put(puncFreeWord, 1);
        } else {
            wordCounts.put(puncFreeWord, wordCounts.get(puncFreeWord) + 1);
        }
    }

    System.out.println(wordCount + " words");
    System.out.println(letterCount + " letters");
    System.out.println(symbolCount + " symbols");
    System.out.println("Top three words: " + printMostUsed(wordCounts));
    System.out.println("Top three letters: " + printMostUsed(letterCounts));

    System.out.println("Words only used once: " + getUniqueCount(wordCounts));
    System.out.print("Letters not used in the document: ");
    for(Character c : chars) {
        System.out.print(c + " ");
    }

    long end = new Date().getTime();
    System.out.print("\n\n");
    System.out.println("Time Taken: " + (end - start) + " milliseconds");
}

    private static String printMostUsed(Map<String, Integer> map) {
    int[] topWordCounts = new int[]{0, 0, 0};
    String[] topWords = new String[]{"", "", ""};

    for(String word : map.keySet()) {
        if(map.get(word) >= topWordCounts[0]) {
            topWords[2] = topWords[1];
            topWords[1] = topWords[0];
            topWordCounts[2] = topWordCounts[1];
            topWordCounts[1] = topWordCounts[0];
            topWords[0] = word;
            topWordCounts[0] = map.get(word);
        } else if(map.get(word) >= topWordCounts[1]) {
            topWords[2] = topWords[1];
            topWordCounts[2] = topWordCounts[1];
            topWords[1] = word;
            topWordCounts[1] = map.get(word);
        } else if(map.get(word) >= topWordCounts[2]) {
            topWords[2] = word;
            topWordCounts[2] = map.get(word);
        }
    }

    return topWords[0] + " (" + topWordCounts[0] + " counts), " + topWords[1] + " (" + topWordCounts[1] + " counts), "
            + topWords[2] + " (" + topWordCounts[2] + " counts)";
}

private static int getUniqueCount(Map<String, Integer> map) {
    int uniqueCount = 0;
    for(Map.Entry<String, Integer> entry : map.entrySet()) {
        if(entry.getValue() == 1) {
            uniqueCount++;
        }
    }
    return uniqueCount;
}

Output:

3002 words
16570 letters
624 symbols
Top three words: ut (56 counts), sed (53 counts), in (53 counts)
Top three letters: e (1921 counts), i (1703 counts), u (1524 counts)
Words only used once: 13
Letters not used in the document: k w x y z

share
Save
NUNTIUMNECAVI
7 points·4 years ago·edited 4 years ago

Quickly hacked together, inefficient and non-robust Python solution:

#!/usr/bin/env python

from os import path
from sys import argv, stdin
from StringIO import StringIO
from collections import Counter
from string import letters
import re

def analyze_words(_input=stdin):
    content = _input.read()
    words = re.findall(r'([\w]+)', content)
    nonwords = re.findall(r'([^\w\s]+)', content)
    firstwords = [words[0]] + re.findall(r'\n\s*\n\s*([\w]+)', content)
    unusedletters = filter(lambda c: c not in content.lower(), letters[:26])

    print '{0} words\n{1} letters\n{2} symbols\nTop three most common words: '\
        '{3}\nTop three most common letters: {4}\n{5} is the most common firs'\
        't word of all paragraphs\nWords only used once: {6}\nLetters not use'\
        'd in the document: {7}'.format(
            len(words), sum(map(len, words)), sum(map(len, nonwords)),
            ', '.join(w for w, _ in Counter(words).most_common(3)),
            ', '.join(w for w, _ in Counter(''.join(words)).most_common(3)),
            Counter(firstwords).most_common(1)[0][0],
            ', '.join(w for w, c in Counter(words).items() if c == 1),
            ', '.join(unusedletters))


if __name__ == '__main__':
    if path.exists(argv[1]):
        _input = open(argv[1])
    else:
        _input = StringIO(argv[1])

    analyze_words(_input)

Sample input:

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

Sample output:

$ python words.py Document.txt
69 words
370 letters
8 symbols
Top three most common words: in, dolore, ut
Top three most common letters: i, e, t
Lorem is the most common first word of all paragraphs
Words only used once: ad, irure, ea, officia, sunt, elit, sed, eiusmod, enim, eu, et, labore, adipisicing, incididunt, reprehenderit, est, quis, sit, nostrud, id, consectetur, aute, Duis, mollit, aliquip, nulla, Lorem, laborum, do, non, commodo, aliqua, Ut, sint, velit, cillum, veniam, consequat, magna, qui, ullamco, deserunt, amet, ipsum, nisi, fugiat, occaecat, proident, minim, culpa, tempor, pariatur, laboris, anim, cupidatat, Excepteur, voluptate, esse, exercitation, ex
Letters not used in the document: j, k, w, y, z

Edit: Another run with 30 paragraphs of lorem ipsum (pastebin):

$ python words.py lipsum.txt
3002 words
16571 letters
624 symbols
Top three most common words: amet, sit, et
Top three most common letters: e, i, u
Vestibulum is the most common first word of all paragraphs
Words only used once: litora, torquent, nostra, himenaeos, sociosqu, Class, aptent, inceptos, conubia, taciti, ad, potenti
Letters not used in the document: k, w, x, y, z

share
Save
dante9999
3 points·4 years ago·edited 4 years ago

Nice solution.

I see that you made an interesting use of this collection module (eg Counter) I
have to read more about it, does it work the same way as some_string.count
(occurences_of_something)? Why do you think your solution is inefficient?
Regular expressions are pretty efficient, aren't they?

share
Save
NUNTIUMNECAVI
4 points·4 years ago

collections.Counter was just convenient. You could generate a frequency dict
pretty easily using str.count and in a multitude of other ways, but Counter
does all the dirty work for you.

As for efficiency, this works well for small files, but I think I could've made
it a bit more scalable. There's a bit of redundancy (generating identical
Counter frequency dicts, using Counter at all is unnecessary on some of these
from a memory usage standpoint, calling str.lower() on the entire text 26
times, etc.). I also think I could've done this while iterating through the
file instead of storing the entire thing in memory.

Additionally, the code could also have been structured a lot better and handled
edge cases (e.g. not crash on empty files).

share
Save
NUNTIUMNECAVI
2 points·4 years ago·edited 4 years ago

Another solution that's a little slower, but a lot more memory efficient:

#!/usr/bin/env python

from sys import stdin
from string import letters
from heapq import nlargest
import re

class WordAnalyzer:
    def __init__(self, fd):
        self._fd = fd
        self._word_re = re.compile(r'([\w]+)')
        self._start_word_re = re.compile(r'(?:^\s*)([\w]+)')
        self._nonword_re = re.compile(r'([^\w\s]+)')
        self._reset_all()

    def _reset_all(self):
        self._word_freq_dict = dict()
        self._letter_freq_dict = dict()
        self._para_word_freq_dict = dict()
        self._nsymbols = 0

    def _build_freq_dicts(self, s, new_paragraph=True, ignore_case=True):
        for w in (m.group() for m in
                  self._word_re.finditer(s.upper() if ignore_case else s)):
            self._word_freq_dict[w] = 1 + \
                (self._word_freq_dict[w]
                     if self._word_freq_dict.has_key(w)
                     else 0)
            for c in w:
                self._letter_freq_dict[c] = 1 + \
                    (self._letter_freq_dict[c]
                         if self._letter_freq_dict.has_key(c)
                         else 0)
        if new_paragraph:
            for w in self._start_word_re.findall(s.upper() if ignore_case
                                                 else s):
                self._para_word_freq_dict[w] = 1 + \
                    (self._para_word_freq_dict[w]
                         if self._para_word_freq_dict.has_key(w)
                         else 0)

    def _count_words(self):
        return sum(self._word_freq_dict.itervalues())

    def _count_letters(self):
        return sum(self._letter_freq_dict.itervalues())

    def _count_symbols(self, s):
        self._nsymbols += \
            sum(map(len, (m.group() for m in self._nonword_re.finditer(s))))

    def print_stats(self, ignore_case=True):
        self._reset_all()
        with open(self._fd, 'r') as f:
            prev_line_empty = True
            for l in f:
                self._build_freq_dicts(l, new_paragraph=prev_line_empty,
                                       ignore_case=ignore_case)
                self._count_symbols(l)
                prev_line_empty = l.strip() == ''

        print('{0} words'.format(self._count_words()))
        print('{0} letters'.format(self._count_letters()))
        print('{0} symbols'.format(self._nsymbols))
        print('Top three most common words: {0}'.format(', '.join(
            nlargest(3, self._word_freq_dict, key=self._word_freq_dict.get))))
        print('Top three most common letters: {0}'.format(', '.join(
            nlargest(3, self._letter_freq_dict,
                     key=self._letter_freq_dict.get))))
        print('{0} is the most common first word of all paragraphs'.format(
            nlargest(1, self._para_word_freq_dict,
                     key=self._para_word_freq_dict.get)[0]))
        print('Words only used once: {0}'.format(', '.join(
            w for w, c in self._word_freq_dict.iteritems() if c == 1)))
        print('Letters not used in the document: {0}'.format(', '.join(filter(
            lambda c: c.upper() not in
                (l.upper() for l in self._letter_freq_dict.iterkeys()),
            letters[26:]))))

if __name__ == '__main__':
    from os import path
    from sys import argv
    from StringIO import StringIO

    try:
        _input = argv[1]
    except IndexError:
        _input = raw_input("File: ")

    WordAnalyzer(_input).print_stats()

Using this solution on this file (warning: enormous .txt file) takes 3.3
seconds and uses 8,465,288 bytes of memory. My first solution (in the post
above) needs 2.9 seconds and 71,680,240 bytes of memory.

Edit: Fixed a bug.

share
Save
Comment deleted4 years ago
d347hm4n
1 point·4 years ago

remove

share
Save
prometheus_flame
3 points·4 years ago

In Ruby, first time submitting, no bonus:

puts "File location please:"

location = gets.chomp

data = ""
File.foreach(location){|line| data += line.downcase} # data is a string with all of the text file in it.


def wordcount(data)
        long = data.split(" ").length
        puts "there are #{long} words in your file"
end

def charcount(data)
        count = data.split("").delete_if {|x| /[^a-z]/.match(x) }.length
        puts "there are #{count} letters (No spaces or punctuation) in your file"
end

def symcount(data)
        count = data.split("").delete_if {|x| /[^[[:punct:]]]/.match(x) }.length
        puts "there are #{count} symobols in your file"
end

def topwords(data)
        words = data.gsub(/[[:punct:]]/, '').split(" ") #words now has all words, punctuation removed.
        repeats = Hash.new(0)
        words.each {|v| repeats[v] +=1 }
        top = repeats.sort_by{|word, repeat| repeat}
        puts "The top three words were:"
        3.times {puts top.pop.to_s}
end

def topchar(data)
        char = data.gsub(/[^a-z]/, '').split("")
        repeats = Hash.new(0)
        char.each {|v| repeats[v] +=1 }
        top = repeats.sort_by{|char, repeat| repeat}
        puts "The top three characters were:"
        3.times {puts top.pop.to_s}
end

if (data.length >= 1)
        wordcount(data)
        charcount(data)
        symcount(data)
        topwords(data)
        topchar(data)
else
        puts "The file appears to be empty"
end

I used the input:

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor
incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis
nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.
Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu
fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in
culpa qui officia deserunt mollit anim id est laborum.

Output:

there are 69 words in your file
there are 370 letters (No spaces or punctuation) in your file
there are 8 symobols in your file
The top three words were:
["in", 3]
["ut", 3]
["dolore", 2]
The top three characters were:
["i", 43]
["e", 38]
["t", 32]

share
Save
the_mighty_skeetadon
3 points·4 years ago

Nice! Little hint -- the ARGV constant stores command-line arguments as an
array. So this command:

    ruby word_stats.rb huckleberry_finn.txt

Has its set of arguments available inside of it through ARGV:

    ARGV[0] => 'huckleberry_finn.txt'

How does this work for you? All you have to do to read a file is this:

    data = File.read(ARGV[0])

If they type a wrong filename, you'll just get an exception.

share
Save
prometheus_flame
2 points·4 years ago

Thanks for the hint, I find that most of my time spent doing these challenges
is just finding methods that do what I need and then finding solutions, like
your rather dashing one, which use more elegant methods that I have yet to
learn about, I should really just read all of the documentation.

share
Save
the_mighty_skeetadon
2 points·4 years ago

Finding all of the fun methods is what makes Ruby great =). I love that there
are several fun, elegant ways to fix things. By the way, your hash method is
probably better than the way I solve it for longer files, as I found out when I
tried to brute force it on a novel =).

share
Save
kaf3ii
3 points·4 years ago·edited 4 years ago

My Haskell solution, critique and comments are very appreciated!

{-# LANGUAGE TemplateHaskell #-}
{-# LANGUAGE TupleSections #-}
import Data.Map (Map)
import qualified Data.Map as M
import Data.List (sort,sortBy,intercalate)
import Data.Ord (comparing)
import Control.Lens
import Control.Monad.State
import Data.Char
import System.Environment (getArgs)

data S = S
  { _newParagraph :: Bool
  , _nWords :: Int
  , _nLetters :: Int
  , _nSymbols :: Int
  , _freqWords :: Map String Int
  , _freqLetter :: Map Char Int
  , _freqPWords :: Map String Int
  }

makeLenses ''S

execStateS :: [TextToken] -> S
execStateS s = execState (pline s) (S True 0 0 0 M.empty M.empty M.empty)

pline :: [TextToken] -> State S ()
pline = mapM_ $ \ttoken -> case ttoken of
  NewParagraph -> newParagraph .= True
  Symbol _     -> nSymbols += 1
  Word str     -> do
    b <- newParagraph <<.= False
    when b $ freqPWords %= add str
    nWords += 1
    freqWords %= add str
    forM_ str $ \c -> do
      nLetters += 1
      freqLetter %= add c

add :: Ord k => k -> Map k Int -> Map k Int
add x = M.insertWith (+) x 1

showS :: S -> String
showS s = let get = (s ^.)
              f toString n = intercalate ", " . take n . map (toString . fst)
                  . sortBy (flip (comparing snd)) . M.toList
          in unlines
  $ (show (get nWords)   ++ " words")
  : (show (get nLetters) ++ " letters")
  : (show (get nSymbols) ++ " symbols")
  : ("The 3 most common words are: "                  ++ f id    3 (get freqWords))
  : ("The 3 most common letters are: "                ++ f (:[]) 3 (get freqLetter))
  : ("The most common first word of a paragraph is: " ++ f id    1 (get freqPWords))
  : ("Words use only once: " ++ (intercalate ", " . map fst . filter ((==1) . snd) . M.toList $ get freqWords))
  : ("Letters not used: " ++ (show $ filter (`M.notMember` get freqLetter) allLetters))
  : []

data TextToken
  = Word   String
  | Symbol Char
  | NewParagraph

tokens :: String -> [TextToken]
tokens str = case str of
    [] -> []
    '\n':'\n':cs -> NewParagraph : tokens cs
    c:cs | isSymbol c -> Symbol c : tokens cs
        | isLetter c -> let (l,r) = span isLetter cs in Word (c:l) : tokens r
        | otherwise  -> tokens cs

allLetters :: [Char]
allLetters = ['a'..'z'] ++ ['A'..'Z']

main :: IO ()
main = do
  file:_ <- getArgs
  readFile file >>= putStr . showS . execStateS . tokens

edit: removed a redundant case match, and reads a file instead of stdin, added
missing bonus assignments

edit: now only reads words as "strings of letters" in contrast to "strings of
nonspace"

share
Save
kaf3ii
2 points·4 years ago·edited 4 years ago

Without template haskell, and State monad, shorter, wider, faster

{-# LANGUAGE TupleSections #-}
import Data.Map (Map)
import qualified Data.Map as M
import Data.List (sort,sortBy)
import Data.Char
import Data.Ord (comparing)
import System.Environment (getArgs)

line :: Bool -> Int -> Int -> Int -> Map String Int -> Map Char Int -> Map String Int -> [[String]] -> (Int, Int, Int, Map String Int, Map Char Int, Map String Int)
line isNewParagraph nWords nLetters nSymbols freqWords freqLetters freqPWords lines = case lines of
  [] -> (nWords,nLetters,nSymbols,freqWords,freqLetters,freqPWords)
  words:ls -> case words of
    []  -> line True nWords nLetters nSymbols freqWords freqLetters freqPWords ls
    w:_ -> let chars = concat words
              letters = filter isLetter chars
              symbols = filter isSymbol chars
            in line False (nWords + length words)
                          (nLetters + length letters)
                          (nSymbols + length symbols)
                          (unionAdd freqWords words)
                          (unionAdd freqLetters letters)
                          ((if isNewParagraph then M.insertWith (+) w 1 else id) freqPWords)
                          ls

unionAdd :: Ord k => Map k Int -> [k] -> Map k Int
unionAdd m lst = M.unionWith (+) m . M.fromAscListWith (+) . map (,1) $ sort lst

showResult :: (Int, Int, Int, Map String Int, Map Char Int, Map String Int) -> String
showResult (nWords,nLetters,nSymbols,freqWords,freqLetters,freqPWords)
  = let f n = unwords . take n . map (show . fst)
            . sortBy (flip (comparing snd)) . M.toList
    in unlines
  $ (show nWords ++ " words")
  : (show nLetters ++ " letters")
  : (show nSymbols ++ " symbols")
  : ("The 3 most common words are: "                  ++ f 3 freqWords)
  : ("The 3 most common letters are: "                ++ f 3 freqLetters)
  : ("The most common first word of a paragraph is: " ++ f 1 freqPWords)
  : ("Words only used once: " ++ (show . map fst . filter ((==1) . snd) $ M.toList  freqWords))
  : ("Letters not used: " ++ (show $ filter (`M.notMember` freqLetters) allLetters))
  : []

allLetters :: [Char]
allLetters = ['a'..'z'] ++ ['A'..'Z']

main :: IO ()
main = do
  f:_ <- getArgs
  readFile f >>= putStr . showResult . line True 0 0 0 M.empty M.empty M.empty . map words . lines

share
Save
The-Cake
2 points·4 years ago

My Haskell solution

import Data.Char
import Data.List (sortBy, group, sort, intercalate)
import Data.Function (on)
import Data.Ord (comparing)
import System.Environment (getArgs)

replaceL :: Eq a => a -> a -> [a] -> [a]
replaceL match new xs = [if x == match then new else x | x <- xs]

oneLine :: String -> String
oneLine xs = replaceL '\n' ' ' xs

wordCount :: String -> Int
wordCount = length . words

letterCount :: String -> Int
letterCount xs = length [x | x <- xs, isAlpha x]

symbolCount :: String -> Int
symbolCount xs = length [ x | x <- xs, x /= ' ', isSymbol x] where
            isSymbol = not . isAlphaNum

mostPopular :: Ord a => [a] -> [a]
mostPopular = map head . byFrequency  where
            byFrequency = reverse . sortBy (comparing length) . group . sort

topWords :: String -> [String]
topWords  = take 3 . mostPopular . words

topLetters :: String -> [String]
topLetters xs = take 3 [a:"" | a <- mostPopular xs]

main = do
  [f] <- getArgs
  s <- readFile f
  putStr "Word count: "
  print $ wordCount s
  putStr "Letter count: "
  print $ letterCount s
  putStr "Symbol count: "
  print $ symbolCount s
  putStr "Top 3 words: "
  putStrLn $ intercalate ", " $ topWords s
  putStr "Top 3 letters: "
  putStrLn $ intercalate ", " $ topLetters s

share
Save
PoppySeedPlehzr
1 03 points·4 years ago

Python with bonuses and lots of list comprehensions >.> Haven't had copious
amounts of time to test, but I wanted to get this up as it's such a late
submission. I'll be checking it's accuracy through out the day and will edit
appropriately.

import sys, re, string

def analytics(fname):
    lines   = []
    first   = {}
    check_f = True
    c_cnts  = {}  # Individual character counts
    w_cnts  = {}  # Individual word counts
    syms    = 0   # Total Symbol counts
    words   = 0   # Total word count
    letters = 0   # Total letter count
    ascii_l = set(string.ascii_lowercase)

    try:
        lines = open(fname, 'r').readlines()
    except FileNotFoundError as e:
        print("%s was not found.  Exiting." % fname)
        sys.exit
    for line in lines:
        ws = [re.sub(r'[\W_]+', '', x) for x in line.split()]
        if(len(ws) == 0):
            check_f = True
        syms += len(re.findall(r'[\W_]', ''.join(x for x in line.split())))
        for w in ws:
            w = w.lower()
            words += 1
            w_cnts[w] = 1 if w not in w_cnts.keys() else w_cnts[w] + 1
            if check_f:
                first[w] = 1 if w not in first.keys() else first[w] + 1
                check_f = False
            for c in w:
                letters += 1
                c_cnts[c] = 1 if c not in c_cnts.keys() else c_cnts[c] + 1

    w_list = sorted(w_cnts.items(), key=lambda x:x[1], reverse=True) # Reverse sort the dict of words
    c_list = sorted(c_cnts.items(), key=lambda x:x[1], reverse=True) # Reverse sort the dict of characters

    print("%d words" % words)
    print("%d letters" % letters)
    print("%d symbols" % syms)
    print("Top three most common words: \"%s\", \"%s\", \"%s\"" % (w_list[0][0],w_list[1][0],w_list[2][0]))
    print("Top three most common letters: '%s', '%s', '%s'" % (c_list[0][0],c_list[1][0],c_list[2][0]))
    print("%s is the most common first word of all paragraphs" % sorted(first.items(), key=lambda x:x[1], reverse=True)[0][0])
    print("Words were only used once:", [x[0] for x in w_list if x[1] == 1])
    print("Letters were not used in this document: ", {x for x in ascii_l if x not in c_cnts.keys()})

if __name__ == '__main__':
    if(len(sys.argv) != 2):
        print("Usage: %s <Text File Path>" % sys.argv[0])
        sys.exit()
    else:
        analytics(sys.argv[1])

share
Save
az4z3l
3 points·4 years ago

Java - No bonus, since it seemed more tedious than challenging

import java.io.File;
import java.io.FileNotFoundException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.Scanner;

public class Controller {

        public static void main(String[] args) throws FileNotFoundException
        {
                Scanner scn = new Scanner(new File("file.txt"));
                scn.useDelimiter("\\Z");
                String in = scn.next();
                scn.close();
                in.toLowerCase();

                String f = in.replaceAll("\n", " ");

                String[] words = f.split(" ");
                Arrays.sort(words);
                int spaceNum = 0;
                for (String w : words)
                {
                        if (w.equals(""))
                                spaceNum++;
                        else break;
                }

                int count = 1;
                String currWord = words[spaceNum];
                ArrayList<Word> wordCountAry = new ArrayList<Word>();
                for (int i = spaceNum+1 ; i < words.length ; i++)
                {
                        if (words[i].equals(currWord))
                                count++;
                        else
                        {
                                wordCountAry.add(new Word(currWord,count));
                                count = 1;
                                currWord = words[i];
                        }
                }
                Collections.sort(wordCountAry);

                char[] charAry = f.toCharArray();
                Arrays.sort(charAry);
                String sorted = new String(charAry);
                sorted = sorted.trim();
                charAry = sorted.toCharArray();

                int[] charsCount = new int[26];
                int currChar = 0;
                int numChars = 0;
                int numSym = 0;
                for (char c : charAry)
                {
                        if ((c >= '!' && c <= '/') || (c >= ':' && c <= '@') || (c >= '[' && c <= '`') || (c >= '{' && c <= '~'))
                        {
                                numSym++;
                        }
                        else if (c >= 'a' && c <= 'z')
                        {
                                if (c == (currChar+'a'))
                                        charsCount[currChar]++;
                                else currChar = c-'a';
                                numChars++;
                        }
                }

                ArrayList<Word> letterCountAry = new ArrayList<Word>();
                for (int i = 0 ; i < charsCount.length ; i++)
                {
                        letterCountAry.add(new Word(""+(char)('a'+i),charsCount[i]));
                }
                Collections.sort(letterCountAry);

                System.out.println("# of words: " + (words.length-spaceNum));
                System.out.println("# of letters: " + numChars);
                System.out.println("# of symbols: " + numSym);
                System.out.println
                        ("3 Most Common Words: "
                                + wordCountAry.get(0) + ", "
                                + wordCountAry.get(1) + ", "
                                + wordCountAry.get(2)
                        );
                System.out.println
                        ("3 Most Common Letters: "
                                + letterCountAry.get(0) + ", "
                                + letterCountAry.get(1) + ", "
                                + letterCountAry.get(2)
                        );

        }
}

class Word implements Comparable<Word>
{
        String s;
        int c;
        public Word(String str, int count)
        {
                s = str;
                c = count;
        }
        @Override
        public int compareTo(Word arg0) {
                // TODO Auto-generated method stub
                return arg0.c - this.c;
        }
        public String toString()
        {
                return s + " " + c;
        }
}

Just for fun, I tested on the King James Bible

# of words: 824146
# of letters: 3122099
# of symbols: 157405
3 Most Common Words: the 62257, and 38642, of 34553
3 Most Common Letters: e 409521, t 309980, h 279469

share
Save
dindresto
3 points·4 years ago

Python (no bonus):

from __future__ import print_function
from collections import Counter
import re

word_re = re.compile(r"\b[\w-]+\b")
letter_re = re.compile("[a-z]")
symbol_re = re.compile("[^\w\s]")

messages = [
    "Top three most common words: '{0[0][0]}', '{0[1][0]}', '{0[2][0]}'",
    "Top three most common letters: '{0[0][0]}', '{0[1][0]}', '{0[2][0]}'"
]

def analyse(text):
    text = text.lower()
    words = word_re.findall(text)
    word_counter = Counter(words)
    letters = letter_re.findall(text)
    letter_counter = Counter(letters)
    symbols = symbol_re.findall(text)

    print(len(words), "words")
    print(len(letters), "letters")
    print(len(symbols), "symbols")
    print(messages[0].format(word_counter.most_common(3)))
    print(messages[1].format(letter_counter.most_common(3)))

if __name__ == "__main__":
    from sys import argv, exit

    if len(argv) < 2:
        print("Usage:", __file__, "<file>")
        exit(0)

    with open(argv[1], "r") as f:
        analyse(f.read())

share
Save
CactaurJack
5 points·4 years ago

[C#] Object based solution, made it really easy to do the optional stuff with
everything held in objects. Terribly written, way too many static functions but
it works and it's easy to modify.

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.IO;

namespace WordAnalytics
{
  class Program
{

    public static int wordcount = 0;
    public static int lettercount;
    public static int finalWordcount = 0;
    public static int symbolcount = 0;

    static void Main(string[] args)
    {
        string location = args[0];
        StreamReader sr = new StreamReader(location);
        Word[] Words = new Word[1000];
        Letter[] Letters = new Letter[26];
        Letters = PopulateLetters(Letters);
        string input = sr.ReadToEnd();
        sr.Close();
        string wordHold = "";


        for (int i = 0; i < input.Length; i++)
        {
            letterCheck(input[i], Letters);
            if (input[i].Equals(' ') || input[i].Equals('.') || input[i].Equals(','))
            {
                wordCheck(wordHold, wordcount, Words);
                finalWordcount++;
                wordHold = "";
            }
            else
            {
                wordHold += input[i];
            }
        }

        Word[] finalWords = topWords(Words);
        Letter[] finalLetters = topLetters(Letters);

        Console.WriteLine("Letter count = " + lettercount);
        Console.WriteLine("Word count = " + finalWordcount);
        Console.WriteLine("Symbol count = " + symbolcount);
        Console.WriteLine("Three most used words = " + finalWords[0].word + " " + finalWords[1].word + " " + finalWords[2].word);
        Console.WriteLine("Three most used words = " + finalLetters[0].letter + " " + finalLetters[1].letter + " " + finalLetters[2].letter);
        Console.WriteLine("Letters not used = " + noLetters(Letters));
        Console.WriteLine("Words used only once = " + oneWord(Words));
        Console.ReadLine();
    }

    static string noLetters(Letter[] Master)
    {

        string output = "";
        for (int i = 0; i < Master.Length; i++)
        {
            if (Master[i].count == 0)
            {
                output = output + Master[i].letter + ",";
            }
        }

        return output;
    }

    static string oneWord(Word[] Master)
    {
        string output = "";
        for (int i = 0; i < wordcount; i++)
        {
            if (Master[i].count == 1)
            {
                output = output + Master[i].word + ", ";
            }
        }

        return output;
    }

    static Word[] topWords(Word[] Master)
    {
        Word[] Top = new Word[3];
        Top[0] = new Word(" ");
        Top[0] = new Word(" ");
        Top[0] = new Word(" ");
        int compare = 0;
        for (int i = 0; i < wordcount; i++)
        {
            if (Master[i].count > compare  && Master[i].word.Length > 1)
            {
                Top[2] = Top[1];
                Top[1] = Top[0];
                Top[0] = Master[i];
                compare = Master[i].count;
                continue;
            }

            if (Master[i].count > Top[1].count && Master[i].word.Length > 1)
            {
                Top[2] = Top[1];
                Top[1] = Master[i];
                continue;
            }

            if (Master[i].count > Top[2].count && Master[i].word.Length > 1)
            {
                Top[2] = Master[i];
            }
        }
        return Top;
    }

    static Letter[] topLetters(Letter[] Master)
    {
        Letter[] Top = new Letter[3];
        Top[0] = new Letter(' ');
        Top[1] = new Letter(' ');
        Top[2] = new Letter(' ');
        int compare = 0;
        for (int i = 0; i < Master.Length; i++)
        {
            if (Master[i].count > compare)
            {
                Top[2] = Top[1];
                Top[1] = Top[0];
                Top[0] = Master[i];
                compare = Master[i].count;
                continue;
            }

            if (Master[i].count > Top[1].count)
            {
                Top[2] = Top[1];
                Top[1] = Master[i];
                continue;
            }

            if (Master[i].count > Top[2].count)
            {
                Top[2] = Master[i];
            }
        }

        return Top;
    }

    static Letter[] PopulateLetters(Letter[] Master)
    {
        for (int i = 0; i < Master.Length; i++)
        {
            Master[i] = new Letter(Convert.ToChar(i + 97));
        }

        return Master;
    }

    static void wordCheck(string inWord, int count, Word[] Master)
    {
        bool check = false;

        if (wordcount > 1)
        {
            for (int i = 0; i < wordcount; i++)
            {
                check = Master[i].Compare(inWord);
            }
        }

        if (!check)
        {
            Master[count] = new Word(inWord);
            wordcount++;
        }
    }

    static void letterCheck(char inLetter, Letter[] Master)
    {
        //minus 96
        if (Convert.ToInt32(inLetter) < 65 || Convert.ToInt32(inLetter) > 123 || Convert.ToInt32(inLetter) == 95)
        {
            if(!inLetter.Equals(' '))
            {
                symbolcount++;
            }
        }

        else
        {
            int test = Convert.ToInt32(inLetter) - 96;
            if (test < 0)
            {
                test += 32;
            }

            lettercount++;
            Master[test].Increment();
        }
    }
}

class Word
{
    public string word;
    public int count;

    public Word(string _input)
    {
        word = _input;
        count = 1;
    }

    public bool Compare(string _input)
    {
        if (_input.Equals(word))
        {
            count++;
            return true;
        }

        else
        {
            return false;
        }
    }
}

class Letter
{
    public char letter;
    public int count;

    public Letter(char _input)
    {
        letter = _input;
        count = 0;
    }

    public void Increment()
    {
        count++;
    }
}

}

share
Save
skeeto
-9 85 points·4 years ago

JavaScript. First, a handy histogram prototype,

function Histogram(array) {
    this.counts = {};
    array.forEach(function(e) {
        this.counts[e] = (this.counts[e] || 0) + 1;
    }.bind(this));
}

Histogram.prototype.elements = function() {
    return Object.keys(this.counts).sort(function(a, b) {
        return this.counts[b] - this.counts[a];
    }.bind(this));
};

Histogram.prototype.count = function(element) {
    return this.counts[element] || 0;
};

Then the actual word counter,

function identity(x) {
    return x;
}

function count(text) {
    text = text.toLowerCase();
    var words = text.split(/[^\w]+/).filter(identity),
        letters = text.replace(/[^a-zA-Z]+/g, '').split(''),
        wordsHisto = new Histogram(words),
        lettersHisto = new Histogram(letters);
    return {
        words: words.length,
        letters: letters.length,
        symbols: text.replace(/[\w\s]+/g, '').length,
        topWords: wordsHisto.elements().slice(0, 3),
        topLetters: lettersHisto.elements().slice(0, 3),
        once: wordsHisto.elements().filter(function(word) {
            return wordsHisto.count(word) === 1;
        }),
        unused: 'abcdefghijklmnopqrstuvwxyz'.split('')
            .filter(function(letter) {
                return lettersHisto.count(letter) === 0;
            })
    };
}

Output using only the first paragraph. Output in JSON instead of the specified
format, since I'm a rebel.

{
    "words": 124,
    "letters": 702,
    "symbols": 43,
    "topWords": ["aenean", "eget", "ultricies"],
    "topLetters": ["e", "i", "u"],
    "once": ["ipsum", "sit", "amet", ...],
    "unused": ["k", "w", "x", "y", "z"]
}

share
Save
slippery44
4 points·4 years ago

Unrelated to your actual program... I had thought javascript's main use was in
websites and then just included with the html code, but I've noticed javascript
being used for things seemingly unrelated to websites, am I missing one of it's
uses? Or do ppl just like to show off it's versatility?

share
Save
skeeto
-9 86 points·4 years ago

JavaScript was originally created at Netscape in 1995 as a language for
generating dynamic web pages client-side. However, it's grown far beyond that
original role, especially in the last four years. In September 2008 Google
released Chrome along with a brand new JavaScript engine called V8. This new
engine was much more advanced and had incredibly better performance than any
other JavaScript engine at the time. In fact, V8 sometimes beats gcc-compiled C
code. It really raised the bar forcing everyone else to catch up.

In 2009 Node.js was released. Basically, it's a standalone version of V8 with a
bunch of useful libraries for doing things JavaScript doesn't normally do, like
accessing the filesystem, running servers, etc. With this an application can be
written in JavaScript just as it could be written in Python or Ruby. It's a
nice general-purpose programming language: it's object-oriented, it's got
proper lexical closures, and it has decent data structure syntax (i.e. JSON).

Despite what I just said, I don't actually use Node.js myself right now. When I
write JavaScript I connect a browser to my text editor and drive the browser's
JavaScript engine from it.

share
Save
notcaffeinefree
3 points·4 years ago

Your JS always makes me feel so inadequate.

share
Save
oxass
2 points·4 years ago

Check my js out... I'm curious what you think.

link

share
Save
skeeto
-9 83 points·4 years ago

Here are my notes:

  • It's much cleaner to keep the different languages and concerns separated.
    Put your JavaScript in a separate file and include it with a src attribute.
    You're halfway there by looking up DOM elements and attaching handlers
    instead of embedding on* event attributes in the HTML.

  • Be more functional. Rather than pass in a DOM element for the
    getMostCommonWordOrChar function to fill, have the function return the
    computed value and let the caller handle output. What you've done here is
    coupled the core logic of your program with the way the program emits
    output. Your program logic needlessly depends on jQuery and the browser
    DOM. In order to run it in a different environment, like outside of a
    browser, it would need to be modified.

Being more functional also means your code is easier to test. Right now you'd
have to set up a node for output, run your function mutating the node's state,
then verify that the state was mutated appropriately. In the functional version
you just call the function and make sure it returns the right value: much
cleaner.

  • You've hardcoded the number of top words/letters in your logic. In order to
    accomodate computing the top four or more words/letters you would need to
    add another if-else clause to your code. This should be a simple integer
    parameter that could potentially vary at runtime. Think about how to
    rewrite your code logic to do this.

  • This one isn't important, but I'll say it anyway: you don't really need
    jQuery in this case. What you're using jQuery for could easily be done with
    the normal DOM manipulation tools: getElementById(), addEventListener() and
    innerHTML. Since you are using jQuery, that last line at the bottom with
    inputText could take advantage of jQuery's fluent API and chain those
    methods.

share
Save
mercurysinking
2 points·4 years ago

Is there any easier way to get the first index of a list of 2-tuples?

I usually do list comprehensions, but that seems like a silly way to get the
first elements of my tuples. Why doesn't Python support list slicing like this:

>>> a = zip(range(10), range(10))
>>> a
[(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8), (9, 9)]
>>> a[:][0]
    (outputs (0,0))
    (want first element of all tuples)

Anyway, here's my answer. Been a while since I've used regular expressions.

import string
import re

def get_properties(data):
        words = data.split(" ")
        letters = re.findall(r"[a-zA-z]", data)
        specialChars = re.findall(r"[^a-zA-Z0-9 ]", data)

        wordCounts = [(word, words.count(word)) for word in set(words)]
        wordCounts.sort(key=lambda x: x[1])

        letterCounts = [(letter, letters.count(letter)) for letter in set(letters)]
        letterCounts.sort(key=lambda x: x[1])

        onceWords = [word for word,count in wordCounts if count == 1]
        unusedLetters = set(string.letters) - set(letters)

        print "%s words" %(len(words))
        print "%s letters: " %len(letters)
        print "%s symbols" %len(specialChars)
        print "Top 3 words: %s" %', '.join([word for word,_ in wordCounts[-3:][::-1]])
        print "Top 3 letters: %s" %', '.join([letter for letter,_ in letterCounts[-3:][::-1]])
        print "Once words: %s" %', '.join(onceWords)
        print "Unused letters: ", ''.join(unusedLetters)

with open("lorem", "rb") as f:
        data = f.read()
        get_properties(data)


69 words
370 letters:
10 symbols
Top 3 words: in, dolor, ut
Top 3 letters: i, e, t
Once words:
Lorem, ad, irure, ea, officia, sunt, qui, sed, eiusmod, enim, eu, et, aliqua., labore, laborum.
, adipisicing, incididunt, reprehenderit, est, quis, sit, veniam,, nostrud, id, consectetur, aute, Duis, mollit, aliquip, nulla, do, non, commodo, Ut, sint, velit, cillum, pariatur., ex, esse, proident,, magna, cupidatat, ullamco, deserunt, ipsum, amet,, nisi, fugiat, occaecat, minim, culpa, tempor, laboris, anim, consequat., Excepteur, voluptate, exercitation, elit,
Unused letters:  ACBGFIHKJMONQPSRTWVYXZkjwyz

I used the lorem ipsum from u/nuntiumnecavi

share
Save
Arknave
0 01 point·4 years ago

I don't think this is any cleaner than a list comprehension, but worth a post:

map(lambda x: x[0], array)

share
Save
kalgynirae
1 point·4 years ago

And the more-verbose but faster-for-large-sets-of-data variant:

from operator import itemgetter
firsts = map(itemgetter(0), array)

Edit: Here are some examples of when to use itemgetter and attrgetter, in case
you are reading this and aren't familiar with them: http://wiki.python.org/moin
/HowTo/Sorting#Operator_Module_Functions

share
Save
rednaks
0 points·4 years ago

"Unused letters: ACBGFIHKJMONQPSRTWVYXZkjwyz" it's not case sensitive

share
Save
ouimet51
2 points·4 years ago

Having a bit of trouble with the portion Number of symbols (any non-letter and
non-digit character, excluding white spaces). From researching I feel I need to
use REGEX but I am unable to figure out exactly how... Any documentation that
could help me along?

share
Save
the_mighty_skeetadon
2 points·4 years ago

Hey there --

I used the following pattern: [^\w\s] -- that'll catch any character that isn't
whitespace or a word character (which is a-z, A-Z, 1-9).

For learning regexes, www.regular-expressions.info is pretty good.

share
Save
Medicalizawhat
3 points·4 years ago

Rubular is good for experimenting with them as well.

share
Save
moonstne
2 points·4 years ago·edited 4 years ago

My answer in python using NUNTIUMNECAVI's text: pastebin (It is a tad long)

*symbols counter counted spaces by mistake, fixed in output/homecode only.

output:

Please type your text file locationC:\Users\moonstne\Desktop\gibberish.txt
3002 words
16571 letters
624 symbols
Top three most common words: ut,sed,in
Top three most common letters: e,i,u
vestibulum is the most common first word of all paragraphs
Words only used once: ['litora', 'torquent', 'nostra', 'himenaeos',
'sociosqu', 'aptent', 'inceptos', 'conubia', 'taciti', 'ad', 'class', 'potenti']
Letters not used in the document: ['w', 'y', 'k', 'x', 'z']

share
Save
dante9999
2 points·4 years ago·edited 4 years ago

That's a cool task. My solution in Python 2.7 with most of the bonuses without
the use of Regular Expressions.

I get the same output as everyone here, so it seem to work.

import string
import operator

def word_like(file):
words = 0
symbols = 0
letters = 0
common_letters = {}
common_words = {}
used_once = []
used = []

with open(file) as f:
        for line in f:
                line = line.strip().replace("\n","")
                words_in_line = line.split(" ")
                words += len(words_in_line)

                for x in string.punctuation:
                        if x in line:
                                symbols += line.count(x)

                for z in string.ascii_letters:
                        if z in line:
                                letters += line.count(z)
                                common_letters[z] = line.count(z)
                                used.append(z)

                for x in words_in_line:
                        if x in common_words.keys():
                                common_words[x] = += words_in_line.count(x)
                        else:
                                common_words[x] = words_in_line.count(x)

for x in common_words.items():
        if x[1] == 1:
                used_once.append(x[0])

common_letters = sorted(common_letters.iteritems(), key=operator.itemgetter(1))[-3:]
common_words = sorted(common_words.iteritems(), key=operator.itemgetter(1))[-3:]
not_used  = list(set(string.ascii_letters) - set(used))

print "%i words" % (words)
print "%i symbols " % (symbols)
print "%i letters " % (letters)
print "Top three most common words %s,%s,%s" % \
(common_words[-1][0], common_words[-2][0], common_words[-3][0])
print "top three most common letters %s %s %s" % \
(common_letters[2][0], common_letters[1][0], common_letters[0][0])
print "words used only once: %l " % (used_once)
print "letters not used in document: %l" % (not_used)

share
Save
secondsup
2 points·4 years ago

Ruby with bonuses

class String
  def alpha?
    !!match(/^[[:alpha:]]+$/)
  end
  def digit?
    !!match(/^[[:digit:]]+$/)
  end
end

def largest_hash_key(hash)
  max = hash.max_by { |key,value| value }
  max.first unless !max
end

numWords = 0
numLetters = 0
numSymbols = 0

wordFreq = Hash.new(0)
letterFreq = Hash.new(0)
firstWordFreq = Hash.new(0)
nextWord = false

ARGF.each_line do |line|
  line.lstrip!
  if line.empty?
    nextWord = true
    next
  end

  line.downcase!
  splitLine = line.split
  splitLine.each do |word|
    if nextWord
      firstWordFreq[word] += 1
      nextWord = false
    end

    numWords += 1
    wordFreq[word] += 1

    word.each_char do |c|
      if !c.alpha? && !c.digit?
        numSymbols += 1
      elsif c.alpha?
        numLetters += 1
        letterFreq[c] += 1
      end
    end
  end
end

singleOccurances = 0
wordFreq.each_value do |value|
  if value == 1
    singleOccurances += 1
  end
end

puts "Number of words: #{numWords}"
puts "Number of letters: #{numLetters}"
puts "Number of symbols: #{numSymbols}"

print "Letters not used: "
("a".."z").each do |c|
  if !letterFreq.include?(c)
    print "#{c} "
  end
end
puts

commonWord1 = largest_hash_key(wordFreq)
wordFreq.delete(commonWord1);
puts "Most common word: #{commonWord1}"

commonWord2 = largest_hash_key(wordFreq)
wordFreq.delete(commonWord2);
puts "2nd most common word: #{commonWord2}"

commonWord3 = largest_hash_key(wordFreq)
wordFreq.delete(commonWord3);
puts "3rd most common word: #{commonWord3}"

commonLetter1 = largest_hash_key(letterFreq)
letterFreq.delete(commonLetter1);
puts "Most common letter: #{commonLetter1}"

commonLetter2 = largest_hash_key(letterFreq)
letterFreq.delete(commonLetter2);
puts "2nd most common letter: #{commonLetter2}"

commonLetter3 = largest_hash_key(letterFreq)
letterFreq.delete(commonLetter3);
puts "3rd most common letter: #{commonLetter3}"

commonFirstWord = largest_hash_key(firstWordFreq)
puts "Most common first word in paragraph: #{commonFirstWord.capitalize}"

puts "Number of words used only once: #{singleOccurances}"

share
Save
itsthatguy42
2 points·4 years ago·edited 4 years ago

Learning perl because I was bored... I must say, it is almost perfect for this
sort of task. Anyways, my much less than optimal solution with all bonuses but
#6:

#!/usr/bin/perl
# dp125e.plx
use strict;
use warnings;

open FILE, $ARGV[0] or die $!;
my ($wordCount, $letterCount, $symbolCount, $count) = (0, 0, 0, 0); # counts
my (%usedWords, %usedLetters); # hashes
my ($muw, $wuo, $mul)= ("most used words:", "words used once: ", "most used letters:"); # strings

while(<FILE>) {
    # loop for each word
    for (split) {
        $wordCount++;
        $letterCount++ while /\w/g;
        $symbolCount++ while s/\W//g; # replace symbols while counting them
        # lowercase (lc) all words
        if(defined $usedWords{lc $_}) {
            $usedWords{lc $_}++;
        } else {
            $usedWords{lc $_} = 1;
        }
        # loop over the word itself
        for (my $i = 0; $i < length($_); $i++) {
            my $letter = lc substr($_, $i, 1);
            if(defined $usedLetters{$letter}) {
                $usedLetters{$letter}++;
            } else {
                $usedLetters{$letter} = 1;
            }
        }
    }
}

# using the wordsUsed hash sorted in decending order, find the most used words and words used once
for (sort { $usedWords{$b} <=> $usedWords{$a} } keys %usedWords) {
    if($count < 3){
        $muw = "$muw $_ ($usedWords{$_} times)";
        $count++;
    }

    if($usedWords{$_} == 1){
        $wuo = "$wuo$_ ";
    }
}

# using the lettersUsed hash sorted in decending order, find the most used letters
$count = 0;
my @usedLetters;
for (sort { $usedLetters{$b} <=> $usedLetters{$a} } keys %usedLetters) {
    if($count < 3){
        $mul = "$mul $_ ($usedLetters{$_} times)";
        $count++;
    }
    push @usedLetters, $_;
}

# find the difference between an array of all letters and the array of used letters
my @letters = ("a".."z");
my @difference;
my %count;
for (@usedLetters, @letters) {
    $count{$_}++
}
for (keys %count) {
    if($count{$_} == 1) {
        push @difference, $_;
    }
}

# print the results
print "word count:\t$wordCount\n",
       "letter count:\t$letterCount\n",
       "symbol count:\t$symbolCount\n",
       "$muw\n",
       "$mul\n",
       "$wuo\n",
       "letters not used in document: @difference\n";

usage:

perl dp125e.plx 30_paragraph_lorem_ipsum.txt

output:

word count:     3002
letter count:   16571
symbol count:   624
most used words: ut (56 times) in (53 times) sed (53 times)
most used letters: e (1921 times) i (1703 times) u (1524 times)
words used once: inceptos torquent nostra conubia taciti sociosqu himenaeos potenti class ad litora aptent
letters not used in document: w x y k z

share
Save
jkg5150
0 03 points·4 years ago

I've not dived into implementing this myself yet but you're exactly right when
you say

    I must say, it is almost perfect for this sort of task

... because this is where Perl eats.

I'd ask though, what resources are you using to learn Perl? This code has an
"olde worlde Perl" flavour to it, and if you're learning from the classic
resources you're missing out on a lot of new stuff. I'd suggest picking up a
Perl book from the last 3-4 years if you want to take it further, there's loads
of cool stuff around now that wasn't around when most of the best known books
were written :-)

I can dig out some more specific pointers to such, if you're interested --
reply if so :)

share
Save
itsthatguy42
3 points·4 years ago

haha yeah you're probably right about the "olde worlde" feel... I picked up
perl almost on a whim this weekend and started working from one of the first
books I could find for free online, namely Beginning Perl. I really should keep
working with javascript but learning new things is fun and I like how different
programming languages force you to think in different ways... ahem back to the
topic...

I'd love to hear some of the tips you could offer! I would also appreciate
suggestions for more modern resources, if you don't mind my asking :)

share
Save
jkg5150
0 05 points·4 years ago

OK, since I drunkenly offered, a few resources that may help :-)

  • http://perlhacks.com/2013/02/perl-books-2/ is an interesting blog about the
    problem with older Perl books which might be interesting

  • Modern Perl: 2011-2012 edition by u/mr_chromatic is free to read online,
    and the accompanying blog is interesting.

  • I hear good things about http://www.effectiveperlprogramming.com/ but
    haven't been paying enough attention

  • there's plenty quality content on http://blogs.perl.org/ too

  • r/perl exists, but I don't spend a lot of time there myself

  • http://stackoverflow.com/questions/tagged/perl has some 20k Perl related
    questions, mostly with answers, and is worth a search when you get stuck
    :-)

  • slightly surprisingly, there's a Perl group on LinkedIn where questions
    seem to get some decent answers...

  • you may have a local Perl Mongers group, check http://www.pm.org/

There are probably things I've missed, but that should keep you going :-)

share
Save
itsthatguy42
3 points·4 years ago

Looks I'll be plenty busy once I'm done with finals. Thanks for the resources!

share
Save
Somebody__
2 points·4 years ago·edited 4 years ago

I know I'm a bit late to the party, but here's an implementation I made in PHP,
it uses a form to $POST a file for analysis. I tested it with some
auto-generated lipsum text.

Code: http://pastebin.com/hcypsdfW

Live page (hosted on my Raspberry Pi, may not work because my WAN access is
being wonky this week): http://somebody.no-ip.biz/wordAnalytics.php

share
Save
blakeembrey
2 points·4 years ago

First time submitting, so decided to do it using node. Uses data from stdin so
I can just pipe data into it. Any feedback is appreciated.

process.stdin.resume();
process.stdin.setEncoding('utf8');

// Use an object to map the characters to their count
var characters     = {},
    words          = {},
    wordsParagraph = {},
    isWordChar,
    filterObject,
    sortByCount;

filterObject = function (input, callback) {
  var output = {};

  Object.keys(input).forEach(function (value) {
    callback(input[value], value, input) && (output[value] = input[value]);
  });

  return output;
};

sortByCount = function (object) {
  return Object.keys(object).map(function (input) {
    return {
      value: input,
      count: object[input]
    };
  }).sort(function (a, b) {
    // Sort descending
    return b.count - a.count;
  }).map(function (input) {
    return input.value;
  });
};

isWordChar = function (char) {
  var charCode = char.charCodeAt(0);
  // Characters code not between A-Z
  return !(charCode < 65 || charCode > 90);
};

// On each input data chunk, process it using the balance checker
process.stdin.on('data', function (chunk) {
  var word       = '',
      prevSymbol = '\n',
      char,
      charCode;

  for (var i = 0; i < chunk.length; i++) {
    char = chunk[i].toUpperCase();

    // Increment the character count
    characters[char] = (characters[char] || 0) + 1;

    if (!isWordChar(char)) {
      if (word) {
        word && (words[word] = (words[word] || 0) + 1);
        prevSymbol === '\n' && (wordsParagraph[word] = (wordsParagraph[word] || 0) + 1);
        word       = ''; // Reset the current word
      }
      prevSymbol = char;
    } else {
      word += char;
    }
  }
});

process.stdin.on('end', function () {
  var sortedWords    = sortByCount(words),
      sortedLetters  = sortByCount(filterObject(characters, function (_, char) {
        return isWordChar(char);
      })),
      sortedWordPara = sortByCount(wordsParagraph),
      totalWords     = Object.keys(words).reduce(function (memo, word) {
        return memo + words[word];
      }, 0),
      totalLetters   = Object.keys(characters).reduce(function (memo, char) {
        return memo + (isWordChar(char) ? characters[char] : 0);
      }, 0),
      totalSymbols   = Object.keys(characters).reduce(function (memo, char) {
        return memo + (/[^\w\s]/.test(char) ? characters[char] : 0);
      }, 0),
      unusedLetters  = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'.split('').filter(function (char) {
        return !characters[char];
      }),
      onceWords      = Object.keys(words).filter(function (word) {
        return words[word] === 1;
      });

  console.log(totalWords + ' words');
  console.log(totalLetters + ' letters');
  console.log(totalSymbols + ' symbols');
  console.log('Top three most common words: ' + sortedWords.slice(0, 3).join(', '));
  console.log('Top three most common letters: ' + sortedLetters.slice(0, 3).join(', '));
  console.log(sortedWordPara.slice(0, 1)[0] + ' is the most common first word of all paragraphs');
  console.log('Words only used once: ' + onceWords.join(', '));
  console.log('Letters not used in the document: ' + unusedLetters.join(', '));
});

share
Save
bustyLaserCannon
2 points·4 years ago

First submission, did it in C#, all but 6 and 8.

Gave me an oppertunity to test out my LINQ - learnt 'Aggregate' whilst doing
so! Also as you can see I don't get how to ForEach in LINQ but if someone wants
to translate them and tell me how i'd appreciate it.

using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Text.RegularExpressions;
using System.Threading.Tasks;


namespace Reddit_Challenge_125
{
    class Program
    {
    static void Main(string[] args)
    {
        string fileContents = System.IO.File.ReadAllText(args[0]);

        if (fileContents.Length == 0)
            return;

        int words = fileContents.Split(' ').Length;
        var letters = fileContents.Aggregate(0, (totalChars, nextChar) => totalChars + nextChar.ToString().Length);
        var symbols = fileContents.Where(c => !char.IsLetterOrDigit(c) && !char.IsWhiteSpace(c)).Count();

        Dictionary<string, int> wordOccurance = new Dictionary<string, int>();
        foreach (string word in fileContents.Split(' '))
        {
            if (wordOccurance.ContainsKey(word))
                wordOccurance[word]++;
            else
                wordOccurance.Add(word, 0);
        }

        wordOccurance = wordOccurance.OrderByDescending(x => x.Value).ToDictionary(d => d.Key, d => d.Value);
        string topThreeWords = wordOccurance.Keys.Take(3).Aggregate("", (first, next) => first + " " + next + ", ");

        Dictionary<string, int> letterOccurance = new Dictionary<string, int>();
        foreach (char letter in fileContents.ToList())
        {
            if (!char.IsLetterOrDigit(letter))
                continue;

            string sLetter = letter.ToString();

            if (letterOccurance.ContainsKey(sLetter))
                letterOccurance[sLetter]++;
            else
                letterOccurance.Add(sLetter, 0);
        }

        letterOccurance = letterOccurance.OrderByDescending(x => x.Value).ToDictionary(d => d.Key, d => d.Value);
        string topThreeLetters = letterOccurance.Keys.Take(3).Aggregate("", (first, next) => first + " " + next + ", ");

        Console.WriteLine(words + " words\n"
                        + letters + " letters\n"
                        + symbols + " symbols\n"
                        + "Top 3 common words are " + topThreeWords + "\n"
                        + "Top 3 common letters are " + topThreeLetters + "\n");

        int onceUsedWords = 0;
        foreach (KeyValuePair<string, int> word in wordOccurance)
            if (word.Value == 1)
                onceUsedWords++;
        Console.WriteLine("Number of words used once: " + onceUsedWords.ToString());

        Console.ReadKey();
    }


}

}

share
Save
thatusernameisalre
2 points·4 years ago·edited 4 years ago

My attempt in Ruby with all bonuses (hopefully). This is my second entry to the
sub and I hope to become a regular here. Critique/comments heavily encouraged
and appreciated!

word_count, letter_count, symbol_count = 0, 0, 0
word_hash = Hash.new(0)
letter_hash = Hash.new(0)
first_word_hash = Hash.new(0)
singles_hash = Hash.new(0)
unused_letters = []
empty_line = false

ARGF.each_line do |line|
        if line.chomp.empty?
                empty_line = true
        else
                # array of words
                line_array = line.split
                word_count += line_array.size
                if empty_line
                        # strip first word of symbols and add to hash
                        first_word_hash[line_array[0].gsub(/[[:punct:]]/, "").downcase] += 1
                        empty_line = false
                end
                line_array.each do |word|
                        # add to word_hash
                        word_hash[word.gsub(/[[:punct:]]/, "").downcase] += 1
                        word.each_char do |char|
                                # check if letter
                                if char.match(/[[:alpha:]]/)
                                        letter_count += 1
                                        # add to letter_hash
                                        letter_hash[char.downcase] += 1
                                # check if symbol
                                elsif char.match(/[[:punct:]]/)
                                        symbol_count += 1
                                end
                        end
                end
        end
end

# sort hashes
sorted_words = word_hash.keys.sort {|k, v| word_hash[v] <=> word_hash[k]}
sorted_letters = letter_hash.keys.sort {|k, v| letter_hash[v] <=> letter_hash[k]}
sorted_first_words = first_word_hash.keys.sort {|k, v| first_word_hash[v] <=> first_word_hash[k]}

# find singles ;)
word_hash.each do |k, v|
        if v == 1
                singles_hash[k.downcase] = v
        end
end

# find unused letters
("a".."z").each do |a|
        found = false
        letter_hash.keys.each do |c|
                if a == c
                        found = true
                end
        end
        if !found
                unused_letters.push(a)
        end
end

puts "#{word_count} words"
puts "#{letter_count} letters"
puts "#{symbol_count} symbols"
puts "Three most common words: #{sorted_words[0]}, #{sorted_words[1]}, #{sorted_words[2]}"
puts "Three most common letters: #{sorted_letters[0]}, #{sorted_letters[1]}, #{sorted_letters[2]}"
puts "Most common first word: #{sorted_first_words[0]}"
puts "Words used only once: #{singles_hash.keys.join(", ")}"
puts "Unused letters: #{unused_letters.join(", ")}"

Sample input: http://pastebin.com/AukLT3vn

Sample output:

451 words

2159 letters

64 symbols

Three most common words: et, amet, dolor

Three most common letters: e, t, a

Most common first word: lorem

Words used only once: wildcard

Unused letters: f, h, x, z

share
Save
RetroSpock
2 points·4 years ago

I'm struggling with the commonly used words one -- I'm using PHP, here's my
code:

// Echo three most common words
$words = preg_split('/[\s,]+/', $fileStr);
$words = array_count_values($words);
arsort($words);
$words = array_slice($words, 0, 3, true);
foreach($words as $word){
    print_r($word);
}

It's printing the number of times each word is used, rather than the word. Any
ideas?

share
Save
36912
2 points·4 years ago·edited 4 years ago

Here is my solution with bonuses in Python. First post in this subreddit and
I'd love feedback!

share
Save
[deleted]
2 points·4 years ago·edited 4 years ago

Awww man just found this subreddit now!

My attempt in Python. I can see it's long and windy and would I be correct in
saying that I really need to learn OOP? Still struggling to get my head around
it :-(

That said I'm pretty happy with the output, though looks like I'm getting some
different answers scuttles off to check reg-exps aaand I've just noticed I'm
getting no result for 'letters not used'... hmmmmmm

Any help or criticism is most welcome!

#!/usr/bin/env python

import os
import os.path
import sys

import re

from collections import Counter

sys.path.insert(0, 'C:\\Users\\Rory\\Downloads')

input_text = open('C:\\Users\\Rory\\Downloads\\30_paragraph_lorem_ipsum.txt', 'r').read()
lorem_ipsum = input_text.lower()

def word_count(text = lorem_ipsum):
    word_match = re.findall(r"[a-z]+" , text)
    word_occurrences = Counter(word_match) # returns a dic of word occurrences
    occurrences_list = word_occurrences.items() # turns dic into a list
    switched_list = [(x,y) for y,x in occurrences_list]
    switched_list.sort(reverse = True)
    return len(word_match), switched_list


def letter_count(text = lorem_ipsum):
    letter_match = re.findall(r"[a-z]" , text)
    letter_occurrences = Counter(letter_match) # returns a dic of letter occurrences
    occurrences_list = letter_occurrences.items() # turns dic into a list
    switched_list = [(x,y) for y,x in occurrences_list]
    switched_list.sort(reverse=True)
    return len(letter_match), switched_list

def symbol_count(text = lorem_ipsum):
    symbol_count = re.findall(r"[^a-z ]" , text)
    return len(symbol_count)


def top3words(input_list = word_count()[1]):
    result = []
    i = 0
    while i < 3:
        result.append(input_list[i][1])
        i += 1
    return result

def top3letters(input_list = letter_count()[1]):
    result = []
    i = 0
    while i < 3:
        result.append(input_list[i][1])
        i += 1
    return result

def words_used_once(input_list = word_count()[1]):
    list_result = [x[1] for x in input_list if x[0] == 1]
    result = ", ".join(list_result)
    return result

def letters_not_used(input_list = letter_count()[1]):
    list_result = [x[1] for x in input_list if x[0] == 0]
    result = ", ".join(list_result)
    return result



print "%s words" %word_count()[0]
print "%s letters" % letter_count()[0]
print "%s symbols" % symbol_count()
print "Top three most common words: %s, %s, %s" %(top3words()[0], top3words()[1], top3words()[2])
print "Top three most common letters: %s, %s, %s" %(top3letters()[0], top3letters()[1], top3letters()[2])
##"J is the most common first word of all paragraphs", where J is the most common word at the start of all paragraphs in the document (paragraph being defined as a block of text with an empty line above it) (*Optional bonus*)
print "Words only used once: %s" %words_used_once()
print "Letters not used in the document: %s", % letters_not_used()

And the output:

3002 words
16571 letters
682 symbols
Top three most common words: ut, sed, in
Top three most common letters: e, i, u
Words only used once: torquent, taciti, sociosqu, potenti, nostra, litora, inceptos, himenaeos, conubia, class, aptent, ad
Letters not used in the document:

share
Save
debug_assert
2 points·4 years ago·edited 4 years ago

Super late to this, but I felt like doing a random little problem today in
python. I decided to just do it as direct and straightforward as possible:

import re
from collections import OrderedDict
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('-f', '--file', help='File to analyze')
args = vars(parser.parse_args())

file = args['file']
f = open(file, 'r')
contents = f.read()

word_re = '[a-zA-Z]+[\']?[a-zA-Z]*'

# count the number of words
words = re.findall(word_re, contents)
num_words = len(words)
print num_words, "words"

# simply count the number of letters
letters = re.findall('[a-zA-Z]', contents)
num_letters = len(letters)
print num_letters, "letters"

# find the number of symbols using a regexp
symbols = re.findall('[^\w\s]', contents)
num_symbols = len(symbols)
print num_symbols, "symbols"

# perform a unique word count
word_dict = {}

for word in words:
    if word in word_dict:
        word_dict[word] += 1
    else:
        word_dict[word] = 1

# sort the dictionary by value to get top 3
word_ordered_items = \
    OrderedDict(sorted(word_dict.items(), key = lambda t: t[1])).items()

num_unique_words = len(word_ordered_items)

# collect them for display
most_common = []
most_common.append(word_ordered_items[num_unique_words - 1][0])
most_common.append(word_ordered_items[num_unique_words - 2][0])
most_common.append(word_ordered_items[num_unique_words - 3][0])
print "Top three most common words: \
    {0}, {1}, {2}".format(most_common[0], most_common[1], most_common[2])

# break into paragraphs
paragraphs = re.findall('.+[\n+]', contents)

first_words = {}
is_paragraph = True
for paragraph in paragraphs:

    paragraph_words = re.findall(word_re, paragraph)
    if len(paragraph_words) == 0:
        is_paragraph = True
        continue

    if is_paragraph:
        is_paragraph = False
        if not paragraph_words[0] in first_words:
            first_words[paragraph_words[0]] = 1
        else:
            first_words[paragraph_words[0]] += 1

first_word_ordered_items = OrderedDict( \
    sorted(first_words.items(), key = lambda t: t[1])).items()
most_common_first_word = \
    first_word_ordered_items[len(first_word_ordered_items ) - 1]
print "{0} is the most common first word of all \
    paragraphs".format(most_common_first_word[0])

words_used_once = []
for word in word_ordered_items:
    if word[1] > 1:
        break
    words_used_once.append(word[0])
print "words only used once: {0}".format(words_used_once)

# make a dict with all chars listed with 0 count
letter_dict = {}
for i in range(26):
    letter_dict[chr(ord('a') + i)] = 0

for letter in letters:
    letter_dict[letter.lower()] += 1

letter_dict_ordered = OrderedDict( \
    sorted(letter_dict.items(), key = lambda t: t[1])).items()

not_used_letters = []

for letter in letter_dict_ordered:
    if letter[1] > 0:
        break
    not_used_letters.append(letter[0])

print "Letters not used in document: {0}".format(not_used_letters)

share
Save
CatZeppelin
2 points·4 years ago

Can I still be credited for completing this challenge? I only have a few more
functions to complete.

share
Save
nint22
1 2Original Poster2 points·4 years ago

Always feel free to post what you have, and to ask for help or clarification if
needed.

share
Save
godzab
2 points·4 years ago·edited 4 years ago

I know I am too late, but I tried it. Did not have time to do 5. Here it is in
Java:

https://gist.github.com/anonymous/6165726

share
Save
Liiiink
2 points·4 years ago

Heres my attempt, semi commented PHP :D

[Live Demo] (http://apps.swft.co/dailyprogrammer/
Challenge-125-Easy-Word-Analytics.php)

[Source Code] (https://github.com/liiiink/dailyprogrammer/blob/master/
Challenge%20%23125%20%5BEasy%5D%20Word%20Analytics.php)

I've included some Lipsum sample text as a default. Not quite command line but,
maybe next time :S

share
Save
indigochill
2 points·4 years ago

Do things like the newline "/n" count as symbols for part 3 of the output? Or
only human-readable non-alphanumeric characters?

share
Save
nint22
1 2Original Poster1 point·4 years ago

Good question! Only count human-readable non-alphanumeric characters.

share
Save
luke1979
2 points·4 years ago

I'm soooo late but still here's my two cents on C#

    static void Main(string[] args)
    {
        var readLine = Console.ReadLine();
        if (readLine != null){
            string fileName = readLine.Trim();
            var lines = File.ReadAllLines(fileName).ToList();

            int lettersUsedOnce = 0;
            var commonWords = new Dictionary<string, int>();
            var commonFirstWords = new Dictionary<string, int>();
            var commonLetters = new Dictionary<char, int>();
            var lettersNotUsed = new List<char>();
            var symbols = new List<string>();

            foreach (string line in lines){

                IEnumerable<String> words = Regex.Split(line, @"[^\w0-9-]+")
                             .Where(s => !String.IsNullOrEmpty(s));
                if (words.Count()>0){
                    string firstWord = words.ElementAt(0);
                    if (commonFirstWords.ContainsKey(firstWord))
                        commonFirstWords[firstWord] = commonFirstWords[firstWord]++;
                    else
                        commonFirstWords.Add(firstWord, 1);
                }
                var wordsInLine = (from word in words
                       group word by word.ToUpper()
                       into g
                                       select new { key = g.Key, WordCount = g.Count() }).OrderBy(x => x.WordCount).ToDictionary(x => x.key, x => x.WordCount);
                foreach (string word in wordsInLine.Keys){
                    if (commonWords.ContainsKey(word))
                        commonWords[word] = commonWords[word] + wordsInLine[word];
                    else
                        commonWords.Add(word, wordsInLine[word]);

                    foreach (char letter in word)
                    {
                        if (Regex.IsMatch(letter + "", @"[A-Z]+")){
                            if (commonLetters.ContainsKey(letter))
                                commonLetters[letter] = commonLetters[letter]++;
                            else
                                commonLetters.Add(letter, 1);
                        }
                    }
                }
                IEnumerable<String> symbolsInWords = Regex.Split(line, @"[a-zA-Z0-9]+")//@"\W|_")
                             .Where(s => !String.IsNullOrEmpty(s)).Distinct().ToList();

                symbols.AddRange(symbolsInWords.Where(x => !symbols.Contains(x)).ToList());
                var allLetters = new List<char> {'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'};
                lettersNotUsed = allLetters.Where(x => !commonLetters.Select(y=>y.Key).ToList().Contains(x)).ToList();
            }
            Console.WriteLine("Number of words: " + commonWords.Count());
            Console.WriteLine("Number of letters: " + commonLetters.Count());
            Console.WriteLine("Number of symbols: " + symbols.Count());
            var topThreeW = commonWords.OrderByDescending(x => x.Value).Select(x => x.Key).Take(3).ToArray();
            Console.WriteLine("Top three most common words are: " + topThreeW[0] + ", " + topThreeW[1] + " and " +
                              topThreeW[2]);
            var topThreeL = commonLetters.OrderByDescending(x => x.Value).Select(x => x.Key).Take(3).ToArray();
            Console.WriteLine("Top three most common letters are: " + topThreeL[0] + ", " + topThreeL[1] + " and " +
                              topThreeL[2]);
            if (commonFirstWords.Count>0){
                var topCommonFirstWord = commonFirstWords.OrderByDescending(x => x.Value).Select(x => x.Key).First();
                Console.WriteLine(topCommonFirstWord + " is the most common first word of all paragraphs");
            }
            lettersUsedOnce = commonWords.OrderByDescending(x => x.Value).Where(x => x.Value == 1).Count();
            Console.WriteLine("Words only used once: " + lettersUsedOnce);
            Console.Write("Letters not used: ");
            foreach (char c in lettersNotUsed)
            {
                if (c==lettersNotUsed.Last())
                    Console.Write(c);
                else
                    Console.Write(c + ",");
            }
            Console.ReadLine();
        }
    }

share
Save
coolquixotic
2 points·4 years ago

My attempt in java Did task 1,2,3,4,5,7 too lazy to do 8 and 6 >.< - just a few
more lines of code.. <code>public class WordAnalytics {

static HashMap<String, Integer> wordlst = new HashMap<String, Integer>();
//no. of words = sum of values of wordlst
static HashMap<String, Integer> letterlst = new HashMap<String, Integer>();
//no. of letters = sum of values of letterlst
static int symbolC = 0;
static List<String> w = new ArrayList<String>();
static List<String> l = new ArrayList<String>();
static int ww = 0;

public static List read(String dct) throws FileNotFoundException {
    List<String> ls = new ArrayList<String>();
    Scanner scn = new Scanner(new FileReader(dct));
    while (scn.hasNextLine()) {
        ls.add(scn.nextLine());
    }
    return ls;
}

public static void countWord(List<String> sen) {
    for (String s : sen) {
        StringTokenizer st = new StringTokenizer(s);
        while (st.hasMoreTokens()) {
            String g = st.nextToken();
            String ng = g.replaceAll("[^A-Za-z0-9]", "");
            symbolC += g.length() - ng.length();
            countLetter(ng);
            if (!wordlst.containsKey(g)) {
                wordlst.put(g, 1);
            } else {
                wordlst.put(g, wordlst.get(g) + 1);
            }
        }

    }
}

public static void countLetter(String g) {
    for (int i = 0; i < g.length(); i++) {
        String r = Character.toString(g.charAt(i));
        //System.out.println(r);
        if (!letterlst.containsKey(r)) {
            letterlst.put(r, 1);
        } else {
            letterlst.put(r, letterlst.get(r) + 1);
        }
    }
}

public static int count(HashMap<String, Integer> hm) {
    int count = 0;
    for (String g : hm.keySet()) {
        count += hm.get(g);
        if (hm.get(g) == 1) {
            ww++;
        }
    }
    return count;
}

public static String getKey(int value, HashMap<String, Integer> hm, List<String> h) {

    for (String g : hm.keySet()) {
        if (!h.contains(g)) {
            if (hm.get(g) == value) {
                h.add(g);
                return g;
            }
        }
    }
    return null;

}

public static void main(String[] args) throws FileNotFoundException {
    WordAnalytics wa = new WordAnalytics();
    countWord(read("C:/Users/pavitrakumar/Desktop/sample.txt"));
    System.out.println(wordlst);
    System.out.println(letterlst);

    //count of various stuff:
    System.out.println("Word count: " + count(wordlst));
    System.out.println("Letter count: " + count(letterlst));
    System.out.println("Symbol count: " + symbolC);

    //top 3 or most used 3 words:
    List<Integer> Wc = new ArrayList(wordlst.values());
    Collections.sort(Wc);
    Collections.reverse(Wc);
    System.out.println("Count of 3 mostly used words: " + Wc.get(0) + " , " + Wc.get(1) + " , " + Wc.get(2));
    System.out.println("3 mostly used words: " + getKey(Wc.get(0), wordlst, w) + " , " + getKey(Wc.get(1), wordlst, w) + " , " + getKey(Wc.get(2), wordlst, w));

    //top 3 or most used 3 letters:
    List<Integer> Lc = new ArrayList(letterlst.values());
    Collections.sort(Lc);
    Collections.reverse(Lc);
    System.out.println("Count of 3 mostly used letters: " + Lc.get(0) + " , " + Lc.get(1) + " , " + Lc.get(2));
    System.out.println("3 mostly used letters: " + getKey(Lc.get(0), letterlst, l) + " , " + getKey(Lc.get(1), letterlst, l) + " , " + getKey(Lc.get(2), letterlst, l));
    System.out.println("No. of words used only once: " + ww);
}

}</code>

share
Save
BinofBread
2 points·4 years ago

Ruby Solution. Critiques welcome!

def largest_hash_key(hash)
  hash.sort_by{|k,v| v}.reverse
end

def store_or_increment_hash(token, hash)
  if hash.has_key?(token)
      hash.store(token, hash.fetch(token) + 1)
  else
      hash.store(token, 1)
  end
end
file = File.new(ARGV.first, "r")
hash = Hash.new()
while(line = file.gets)
  p "Words: #{line.split(' ').size}"
  chars = 0
  line.each_char do |c|
    next if c == ' '
    store_or_increment_hash(c,hash)
    chars += 1
  end
  p "Letters: #{chars}"
  p "Most common letters: #{largest_hash_key(hash)[0..2].collect{|ind| ind[0]}.join(' ')}"
  hash = Hash.new()
  line.split(' ').each do |word|
    store_or_increment_hash(word.gsub(/[.]/, ""), hash)
  end
  p "Most common words: #{largest_hash_key(hash)[0..2].collect{|ind| ind[0]}.join(' ')}}"
  p "Single occurance words: #{hash.select{|k,v| v == 1}.keys.join(' ')}"
end

Output with some lorem ipsum

"Words: 69"
"Letters: 378"
"Most common letters: i e t"
"Most common words: in ut dolore}"
"Single occurance words: Lorem ipsum sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt labore et magna aliqua Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi aliquip ex ea commodo consequat Duis aute irure reprehenderit voluptate velit esse cillum eu fugiat nulla pariatur Excepteur sint occaecat cupidatat non proident, sunt culpa qui officia deserunt mollit anim id est laborum"

share
Save
deepu460
2 points·4 years ago·edited 4 years ago

Here's my first response to the daily programmer in Java. Feel free to list
ways to shorten the code, because I felt like I programmed a little too much.

Code:

/**
 * This class analyzes a text file and prints the number of words, the number of
 * letters, the number of symbols, & the top 3 most commonly used words and
 * letters.
 */
public class WordAnalyzer {
        /**
         * The main method. Prints the statistics of the text file
         *
         * @param args
         *            - Unused
         */
        public static void main(String[] args) {
                // Wikipedia's lorem-ipsum.
                File file = new File("res/lorem ipsum.txt");
                Scanner scanner = null;
                String[] mostCommen = null;
                int temp = 0;

                scanner = resetScanner(scanner, file);

                if (!(scanner == null)) {
                        // The number of words
                        temp = numOfWords(scanner);
                        System.out.println("Number of words: ".concat(Integer
                                        .toString(temp)));

                        // The number of letters
                        scanner = resetScanner(scanner, file);
                        temp = numOfLet(scanner);
                        System.out.println("Number of letters: ".concat(Integer
                                        .toString(temp)));

                        // The number of symbols
                        scanner = resetScanner(scanner, file);
                        temp = numOfSymbols(scanner);
                        System.out.println("Number of symbols: ".concat(Integer
                                        .toString(temp)));

                        // The most comment words
                        scanner = resetScanner(scanner, file);
                        mostCommen = mostCommenWords(scanner);
                        System.out.print("Most commen words:");

                        for (int ix = 0; ix < mostCommen.length; ix++) {
                                System.out.print(" ".concat(mostCommen[ix]));
                        }
                        System.out.print("\n");

                        // The most commen letters
                        scanner = resetScanner(scanner, file);
                        mostCommen = mostCommenLet(scanner);
                        System.out.print("Most commen letters:");
                        for (int ix = 0; ix < mostCommen.length; ix++) {
                                System.out.print(" ".concat(mostCommen[ix]));
                        }
                        System.out.print("\n");

                }
                // Closes the scanner...
                scanner.close();
        }

        /**
         * This gets the number of words in a doc, if you can supply a scanner
         * that is pointed at the text document.
         *
         * @param s
         *            - The scanner
         * @return The # of words.
         */
        private static int numOfWords(Scanner s) {
                int words = 0;

                while (s.hasNext()) {
                        words += s.nextLine().split(" ").length;
                }

                return words;
        }

        /**
         * This gets the number of letters, if supply a scanner pointed at the
         * text document.
         *
         * @param s
         *            - The scanner
         * @return The # of letters
         */
        private static int numOfLet(Scanner s) {
                char[] charLine;
                String line;
                int letters = 0;

                while (s.hasNext()) {
                        line = s.nextLine().replaceAll(" ", "");
                        charLine = line.toCharArray();

                        for (char c : charLine) {
                                letters += (c < 91 && c > 64 || c < 123 && c > 96) ? 1 : 0;
                        }

                }

                return letters;
        }
        /**
         * This gets the number of symbols, if supply a scanner pointed at the
         * text document.
         *
         * @param s
         *            - The scanner
         * @return The # of symbols
         */
        private static int numOfSymbols(Scanner s) {
                char[] charLine;
                String line;
                int symbols = 0;

                while (s.hasNext()) {
                        line = s.nextLine().replaceAll(" ", "");
                        charLine = line.toCharArray();

                        for (char c : charLine) {
                                symbols += (!(c < 91 && c > 64) || !(c < 123 && c > 96)) ? 1
                                                : 0;
                        }

                }

                return symbols;
        }
        /**
         * This gets the 3 most common words.
         * @param s - The scanner
         * @return A string array of the 3 most common words
         */
        private static String[] mostCommenWords(Scanner s) {
                ArrayList<String> common = new ArrayList<>();
                String temp;
                String[] line;
                String[] topThree = new String[3];
                int[] topThreeAmount = { 0, 0, 0 };
                int instances = 0;

                while (s.hasNext()) {
                        line = s.nextLine().split(" ");

                        for (String string : line) {

                                if (string.length() > 1)
                                        common.add(string);
                        }

                }

                Collections.sort(common);
                temp = common.get(0);

                for (int ix = 0; ix < common.size(); ix++) {
                        if (temp.equalsIgnoreCase(common.get(ix))) {
                                instances++;
                        } else {
                                if (instances > topThreeAmount[0]) {
                                        topThree[0] = temp;
                                        topThreeAmount[0] = instances;
                                        instances = 0;
                                } else if (instances > topThreeAmount[1]) {
                                        topThree[1] = temp;
                                        topThreeAmount[1] = instances;
                                        instances = 0;
                                } else if (instances > topThreeAmount[2]) {
                                        topThree[2] = temp;
                                        topThreeAmount[2] = instances;
                                        instances = 0;
                                } else {
                                        instances = 0;
                                }

                                temp = common.get(ix);
                        }
                }

                return topThree;
        }

        /**
         * This finds the most common letters
         * @param s - The scanner
         * @return A string array of the 3 most common letters
         */
        private static String[] mostCommenLet(Scanner s) {
                ArrayList<String> common = new ArrayList<>();
                String temp1;
                String[] line;
                String[] topThree = new String[3];
                int[] topThreeAmount = { 0, 0, 0 };
                int instances = 0;

                while (s.hasNext()) {
                        line = s.nextLine().split(" ");

                        for (String string : line) {
                                for (char c : string.toCharArray()) {
                                        if (c < 91 && c > 64 || c < 123 && c > 96) {
                                                common.add(String.valueOf(c));
                                        }
                                }
                        }

                }

                Collections.sort(common);
                temp1 = common.get(0);

                for (String string : common) {
                        if (temp1.equalsIgnoreCase(string)) {
                                instances++;
                        } else {
                                if (instances > topThreeAmount[0]) {
                                        topThree[0] = temp1;
                                        topThreeAmount[0] = instances;
                                        instances = 0;
                                } else if (instances > topThreeAmount[1]) {
                                        topThree[1] = temp1;
                                        topThreeAmount[1] = instances;
                                        instances = 0;
                                } else if (instances > topThreeAmount[2]) {
                                        topThree[2] = temp1;
                                        topThreeAmount[2] = instances;
                                        instances = 0;
                                } else {
                                        instances = 0;
                                }

                                temp1 = string;
                        }
                }

                return topThree;
        }
        /**
         * This resets the scanner to the begining of the file.
         * @param scanner - The scanner
         * @param file - The file
         * @return The reset scanner
         */
        private static Scanner resetScanner(Scanner scanner, File file) {
                try {
                        return scanner = new Scanner(file);
                } catch (FileNotFoundException e) {
                        System.out.println("Cannot find the file. Quitting...");
                        System.exit(-1);
                }
                // Rather unnecessary code, but it won't compile without it.
                return null;
        }

}

share
Save
pisq000
2 points·4 years ago·edited 4 years ago

my solution in python 3:

#!/usr/bin/env python3
#-*- coding:utf-8 -*-
def top(dic,_n=3):
    """
        Helper funcion used to take the top n words/letters/symbols
    """
    n=len(dic) if _n==0 else _n#If n=0 yields all elements in decreasing order
    i=list(iter(dic))#not sure if iter support .sort
    i.sort(key=lambda a,b:cmp(b[1],a[1]))#sort dic by value in deceasing order
    for j in range(n):
        yield i[j][0]#yield the first n values
def onlyUsed(dic,n=1):
    """
        Helper funcion used to take all words/symbols/letters used only n (default 1) times
    """
    for i,j in iter(dic):
        if j==n:yield i
def tot(dic):
    """
        Helper funcion used to compute the total number of words/symbols/letters
    """
    t=0
    for _,i in iter(dic):
        t+=i
    return t
def upgr(dic,k):
    """
        Helper funcion used to upgrade dic[k] or,if it doesn't exist,create it
    """
    if k in dic.keys():dic[k]+=1
    else:dic[k]=1
charset={chr(i) for i in range(255)}#set of ASCII charachter
letters='aAbBcCdDeEfFgGhHiIjJkKlLmMnNoOpPqQrRsStTuUvVwWxXyYzZ0123456789'
        #alphanumeric characters
class analysis:
    """
        Class containing the results of the analysis as dictionaries
        the keys are the words/letters/symbols
        the values are how many times they appears in the document
        you can also inhert from this class to improve the document diagnostic
    """
    def __init__(self,s,casesens=False)
        self.words=dict()#the single words and how many times they appears
        self.lets=dict()#the single letters and how many times they appears
        self.symb=dict()#the symbols and how many times they appears
        self.wp=dict()#the single words that appear at paragraph start
                           #and how many times they appears at paragraph start
        word=''
        np=2#the number of consecutives newlines,intermixed by space
        for _l in s:
            l=_l if casesens else _l.lower()#handle case sensitivity
            if '\n'!=l!=' ':
                upgr(self.lets,l)
                word+=l#word is still not complete
                if l not in letters:upgr(self.symb,l)#l is a symbol
            elif word!='':#word is complete
                if np>1:#this word is the first of a paragraph
                    upgr(self.wp,word)
                np=0
                upgr(self.words,word)
                word=''
            if l=='\n':np+=1
    def nwords(self):return tot(self.words)#request 1
    def nlets(self):return tot(self.lets)#request 2
    def nsym(self):return tot(self.symb)#request 3
    def topwords(self,n=3):return top(self.words,n)#request 4
    def toplets(self,n=3):return top(self.lets,n)#request 5
    def topp(self,n=1):return top(self.wp,n)#request 6
    def onlyWords(self,n=1):return onlyUsed(self.wp,n)#request 7
    def unussedLetters(self):#request 8
        return charset-frozenset(self.lets.keys())
if __name__=='__main__':#used as cli tool
    f=open(args[1])
    a=analysis(f.read())
    f.close()#analysis complete,we don't need f anymore
    print(a.nwords(),' words')
    print(a.nlets(),' letters')
    print(a.nsym(),' symbols')
    print('"Top three most common words:',','.join(a.topwords()))
    print('Top three most common letters:',','.join(a.toplets()))
    print(a.topp()[0],' is the most common first word of all paragraphs')
    print('Words only used once:',','.join(a.onlyWords()))
    print('Letters not used in the document:',','.join(a.unusedLetters()))

of note is that we can improve performance a bit by replacing

        self.symb=dict()#the symbols and how many times they appears

with

        self.symb=0

and

                if l not in letters:upgr(self.symb,l)#l is a symbol

with

                    if l not in letters:self.symb+=1

and

    def nsym(self):return tot(self.symb)#request 3

with

    def nsym(self):return self.symb

share
Save
dznqbit
2 points·4 years ago

Python 2.7 - critiques welcome.

import sys
import re
from collections import defaultdict
from operator import itemgetter

class KillerWordLikeApplicationDocumentAnalyzer():
  def __init__(self, document):
    self.document = document.lower()

  def __words(self):
    return re.sub(r"[^\w|\s]", "", self.document).split()

  def __letters(self):
    return re.sub(r"\W", "", self.document)

  @classmethod
  def __countEntities(cls, list):
    def countOccurence(dict, item):
      dict[item] += 1
      return dict

    return reduce(countOccurence, list, defaultdict(int)).items()

  @classmethod
  def __mostCommonEntities(cls, list):
    return map(
      itemgetter(0),
      sorted(
        KillerWordLikeApplicationDocumentAnalyzer.__countEntities(list),
        key=itemgetter(1), reverse=True
      )
    )

  def wordCount(self):
    return len(self.__words())

  def letterCount(self):
    return len(self.__letters())

  def symbolCount(self):
    return len(re.sub(r"\w|\s", "", self.document))

  def commonWords(self, count):
    return KillerWordLikeApplicationDocumentAnalyzer.__mostCommonEntities(self.__words())[0:count]

  def commonLetters(self, count):
    return KillerWordLikeApplicationDocumentAnalyzer.__mostCommonEntities(self.__letters())[0:count]

  def mostCommonParagraphLeader(self):
    paragraphs = filter(lambda p: len(p) > 0, re.split(r"\n\n", self.document))

    if len(paragraphs) > 0:
      countedEntities = KillerWordLikeApplicationDocumentAnalyzer.__mostCommonEntities(
        map(lambda line: re.match(r"\w+", line).group(0), paragraphs)
      )

      return countedEntities[0]
    else:
      return None

  def uniqueWords(self):
    return map(
      itemgetter(0),
      filter(
        lambda wordAndCount: wordAndCount[1] == 1,
        KillerWordLikeApplicationDocumentAnalyzer.__countEntities(self.__words())
      )
    )

  def unusedLetters(self):
    return list(
      filter(
        lambda letter: self.document.find(letter) < 0,
        "abcdefghijklmnopqrstuvwxyz"
      )
    )

with open(sys.argv[1], "r") as file:
  analyzer = KillerWordLikeApplicationDocumentAnalyzer(file.read())

print("{0} words".format(analyzer.wordCount()))
print("{0} letters".format(analyzer.letterCount()))
print("{0} symbols".format(analyzer.symbolCount()))

formatWord = lambda x: "\"{}\"".format(x)
formatLetter = lambda x: "'{}'".format(x)

commonWords = analyzer.commonWords(3)
if len(commonWords) > 0:
  print("Top three most common words: {0}".format(", ".join(map(formatWord, commonWords))))

commonLetters = analyzer.commonLetters(3)
if len(commonLetters) > 0:
  print("Top three most common letters: {0}".format(", ".join(map(formatLetter, commonLetters))))

commonParagraphLeader = analyzer.mostCommonParagraphLeader()
if commonParagraphLeader:
  print("{0} is the most common first word of all paragraphs".format(formatWord(commonParagraphLeader)))

uniqueWords = analyzer.uniqueWords()
if len(uniqueWords) > 0:
  print("Words used only once: {0}".format(", ".join(map(formatWord, uniqueWords))))

unusedLetters = analyzer.unusedLetters()
if len(unusedLetters) > 0:
  print("Letters not used in this document: {0}".format(", ".join(map(formatLetter, unusedLetters))))

share
Save
Reverse_Skydiver
1 02 points·4 years ago

Late as hell to the party, but here's my java solution:

import java.awt.List;
import java.io.File;
import java.io.IOException;
import java.lang.Character.UnicodeScript;
import java.nio.ByteBuffer;
import java.nio.charset.Charset;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.util.ArrayList;
import java.util.Dictionary;
import java.util.Scanner;


public class C0125_Easy {

        static String paragraph = readFile();

        public static void main(String[] args) {
                System.out.println(getWordsAsArray(paragraph).length + " words. ");
                System.out.println(getWordsAsString(paragraph).length() + " letters. ");
                System.out.println(getSymbolCount(paragraph) + " symbols");
                System.out.println("Most common words are: " + getMostPopularWords()[0] + ", " + getMostPopularWords()[1] + ", " + getMostPopularWords()[2]);
                System.out.println("Most common letters are: " + getMostPopularLetters(paragraph)[0] + ", " + getMostPopularLetters(paragraph)[1] + ", " + getMostPopularLetters(paragraph)[2]);
        }

        public static String readFile(){
                try{
                        return new Scanner(new File("C://Users//user//Desktop//lorem.txt")).useDelimiter("\\A").next();
                } catch(IOException e){
                        return null;
                }
        }

        public static String[] getWordsAsArray(String s){
                return s.split("\\s+");
        }

        public static String getWordsAsString(String s){
                String[] words = getWordsAsArray(s);
                String temp = "";
                for(int i = 0; i < getWordsAsArray(s).length; i++) temp += words[i];
                return temp;
        }

        public static int getSymbolCount(String s){
                String temp = getWordsAsString(s);
                int count = 0;
                for(int i = 0; i < temp.length(); i++)  if(!Character.isLetterOrDigit(temp.charAt(i))) count++;
                return count;
        }

        public static String[] getMostPopularWords(){
                String temp = paragraph;
                String[] words = new String[3];
                for(int i = 0; i < words.length; i++){
                        words[i] = getPopularWord(getWordsAsArray(temp));
                        temp = temp.replace(words[i], "");
                }
                return words;
        }

        public static String getPopularWord(String[] s){
                String[] results = new String[3];

                int[] x = new int[s.length];
                for(int i = 0; i < s.length; i++){
                        x[i] = 0;
                }
                for(int j = 0; j < s.length; j++){
                        for(int i = 0; i < s.length; i++){
                                if(s[j].equals(s[i]) && i != j){
                                        x[j]++;
                                }
                        }
                }
                int max = 0;
                int index = 0;
                for(int i = 0; i < s.length; i++){
                        if(x[i] >= max){
                                max = x[i];
                                index  = i;
                        }
                }
                return s[index];
        }

        public static char[] getMostPopularLetters(String s){
                String temp = getWordsAsString(s).toLowerCase();
                int[] letters = new int[26];
                for(int i = 0; i < temp.length(); i++){
                        if(Character.isLetterOrDigit(temp.charAt(i))){
                                letters[(int)temp.charAt(i)-97]++;
                        }
                }
                int[] lValues = new int[]{0, 0, 0};
                char[] pLetters = new char[3];
                for(int i = 0; i < letters.length; i++){
                        if(letters[i] > lValues[0]){
                                lValues[2] = lValues[1];
                                lValues[1] = lValues[0];
                                lValues[0] = letters[i];

                                pLetters[2] = pLetters[1];
                                pLetters[1] = pLetters[0];
                                pLetters[0] = (char)(i+97);
                        } else if(letters[i] > lValues[1]){
                                lValues[2] = lValues[1];
                                lValues[1] = letters[i];

                                pLetters[2] = pLetters[1];
                                pLetters[1] = (char)(i+97);
                        } else if(letters[i] > lValues[2]){
                                lValues[2] = letters[i];
                                pLetters[2] = (char)(i+97);
                        }
                }
                return pLetters;
        }
}

This is the result:

3002 words.
17195 letters.
624 symbols
Most common words are: sit, et, vitae
Most common letters are: e, i, u

share
Save
aholmer
2 points·4 years ago·edited 4 years ago

Did this simple version in c#

using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Text;
using System.Text.RegularExpressions;
using System.Threading.Tasks;

namespace WordAnalytics
{
        class Program
        {
                static int Main(string[] args)
                {
                        if (args.Length != 1)
                                return -1;

                        string filename = args[0];

                        if (!File.Exists(filename))
                                return -1;

                        string[] filecontent = File.ReadAllLines(filename);

                        int totalWords = 0, totalLetters = 0, totalSymbols = 0;

                        Dictionary<string, int> popWords = new Dictionary<string, int>();
                        Dictionary<char, int> popLetters = new Dictionary<char, int>();

                        foreach (string line in filecontent)
                        {
                                totalWords += (Regex.Matches(line, "\\w+")).Count;
                                totalLetters += line.Count(Char.IsLetter);
                                totalSymbols += line.Count() - line.Count(Char.IsLetterOrDigit);

                                String[] words = Regex.Replace(line, @"[^A-Za-z0-9\s]", "").Split(' ');
                                foreach (string word in words)
                                {
                                        if (!popWords.ContainsKey(word))
                                                popWords.Add(word, 1);
                                        else
                                                popWords[word] ++;

                                        String letters = Regex.Replace(line, @"[^A-Za-z]", "");
                                        foreach (char letter in letters)
                                        {
                                                if (!popLetters.ContainsKey(letter))
                                                        popLetters.Add(letter, 1);
                                                else
                                                        popLetters[letter] ++;
                                        }
                                }
                        }

                        Console.WriteLine(totalWords + " words");
                        Console.WriteLine(totalLetters + " letters");
                        Console.WriteLine(totalSymbols + " symbols");

                        popWords = popWords.OrderByDescending(x => x.Value).ToDictionary(x => x.Key, x => x.Value);

                        Console.WriteLine("Top three most common words: \"" +
                                                                popWords.Keys.ElementAt(1) + "\", \"" +
                                                                popWords.Keys.ElementAt(2) + "\", \"" +
                                                                popWords.Keys.ElementAt(3) + "\"");

                        popLetters = popLetters.OrderByDescending(x => x.Value).ToDictionary(x => x.Key, y => y.Value);

                        Console.WriteLine("Top three most common letters: \"" +
                                                                popLetters.Keys.ElementAt(0) + "\", \"" +
                                                                popLetters.Keys.ElementAt(1) + "\", \"" +
                                                                popLetters.Keys.ElementAt(2) + "\"");

                        Console.ReadKey();
                        return 0;
                }
        }
}

share
Save
Reads_Small_Text_Bot
1 point·4 years ago


    A-Za-z0-9\s A-Za-z

share
Save
lawlrng
0 13 points·4 years ago·edited 4 years ago

Python solution. Input and output are the same as u/nuntiumnecavi

import collections
import operator
import string
import sys

class FileParser:
    def __init__(self, the_file, case_sens = False):
        self.words = self.letters = self.symbols = 0
        self.word_freq = collections.defaultdict(int)
        self.letter_freq = collections.defaultdict(int)
        self.paragraph = collections.defaultdict(int)
        self.letters_used = set()
        self.base_letters = set([string.ascii_lowercase, string.ascii_letters][case_sens])
        self._parse_file(open(the_file), case_sens)

    def _count_letters(self, line):
        return len([a for a in line if a in string.ascii_letters])

    def _count_symbols(self, line):
        return len([a for a in line if a in string.punctuation])

    def _parse_file(self, a_file, case):
        if not case: a_file = [c.lower() for c in a_file]

        in_paragraph = True
        for line in a_file:
            tmp = line.split()

            if not tmp: # Blank line
                in_paragraph = True
                continue

            if in_paragraph:
                self.paragraph[tmp[0]] += 1
                in_paragraph = False

            self.words += len(tmp)
            self.letters += self._count_letters(line)
            self.symbols += self._count_symbols(line)
            self.letters_used.update(a for a in line if a in string.letters)
            for w in tmp:
                self.word_freq[w.strip(string.punctuation)] += 1
                for c in w:
                    if c in string.ascii_letters:
                        self.letter_freq[c] += 1

    def _get_top_three(self, dic):
        top_3 = sorted(dic.iteritems(), key=operator.itemgetter(1))[-3:]
        return ', '.join(f for f, l in top_3)

    def print_results(self):
        print "{} words".format(self.words)
        print "{} letters".format(self.letters)
        print "{} symbols".format(self.symbols)
        print "Top three most common words: {}".format(self._get_top_three(self.word_freq))
        print "Top three most common letters: {}".format(self._get_top_three(self.letter_freq))
        print "{} is the most common first word of all paragraphs".format(max(self.paragraph.iteritems(), key=operator.itemgetter(1))[0])
        print "Words only used once: {}".format(', '.join(k for k, v in self.word_freq.items() if v == 1))
        print "Letters not used in the document: {}".format(', '.format(self.base_letters - self.letters_used))

if __name__ == '__main__':
    try:
        fn = sys.argv[1]
    except IndexError:
        fn = raw_input("File name: ")

    fp = FileParser(fn, False)
    fp.print_results()

share
Save
the_mighty_skeetadon
2 points·4 years ago·edited 4 years ago

Simple, but not particularly efficient (in Ruby):

text = File.read(ARGV.first).downcase #downcase to make comparisons non-case-sensitive

words = text.scan(/\w+\b/)
letters = text.scan(/\w/)
symbols = text.scan(/[^\w\s]/)
first_words = text.scan(/(?<=\n\n)\w+\b/)
most_common_words = words.uniq.map { |x| [x,words.count(x)] }.sort_by { |freq| freq[1]*(-1) }
most_common_letters = letters.uniq.map { |x| [x,letters.count(x)] }.sort_by { |freq| freq[1]*(-1) }
most_common_first_words = first_words.uniq.map { |x| [x,first_words.count(x)] }.sort_by { |freq| freq[1]*(-1) }

unique_words = words.select { |word| words.count(word) == 1 }
unused_letters = ('a'..'z').to_a.reject {|x| letters.include?(x)}

puts "Word statistics for #{ARGV.first}:
#{words.length} words
#{letters.length} letters
#{symbols.length} symbols
Top three most common words: #{most_common_words[0][0]} (#{most_common_words[0][1]} times), #{most_common_words[1][0]} (#{most_common_words[1][1]} times), #{most_common_words[2][0]} (#{most_common_words[2][1]} times).
Top three most common letters: #{most_common_letters[0][0]} (#{most_common_letters[0][1]} times), #{most_common_letters[1][0]} (#{most_common_letters[1][1]} times), #{most_common_letters[2][0]} (#{most_common_letters[2][1]} times).
#{most_common_first_words[0][0]} is the most common first word of all paragraphs, appearing #{most_common_first_words[0][1]} times.
Words only used once: #{unique_words.join(', ')}
Letters not used in the document: #{unused_letters.join(', ')}"

If I were going to do it again, I'd store uniques in hashes, then sum their
counts and whatnot. That way it wouldn't take a couple minutes to analyze
huckleberry finn...

I guess you might want output, too:

Word statistics for .\huckleberry_finn_short.txt:
12001 words
49224 letters
2786 symbols
Top three most common words: the (612 times), i (355 times), and (346 times).
Top three most common letters: e (6080 times), t (4348 times), a (4007 time).
i is the most common first word of all paragraphs, appearing 10 times.
Words only used once: anywhere, cost, ...(redacted because there are thousands)
Letters not used in the document:

share
Save
kalgynirae
2 points·4 years ago·edited 4 years ago

Python 3 solution. No regular expressions! collections.Counter is helpful here.

#!/usr/bin/python3
from collections import Counter
from string import ascii_lowercase, punctuation, whitespace
import sys

with open(sys.argv[1]) as f:
    text = f.read().lower()

words = [w.strip(punctuation) for w in text.split()]
letters = [c for c in text if c in ascii_lowercase]
data = {
    "words": len(words),
    "letters": len(letters),
    "symbols": sum(1 for c in text if c not in ascii_lowercase and
                                       c not in whitespace),
    "common_words": ", ".join(t[0] for t in Counter(words).most_common(3)),
    "common_letters": ", ".join(t[0] for t in Counter(letters).most_common(3)),
    "once_words": ", ".join(t[0] for t in Counter(words).items() if t[1] == 1),
    "unused_letters": ", ".join(set(ascii_lowercase) - set(letters)),
}

items = ["{words} words", "{letters} letters", "{symbols} symbols",
         "Top three most common words: {common_words}",
         "Top three most common letters: {common_letters}",
         "Words only used once: {once_words}",
         "Letters not used in the document: {unused_letters}"]
print("\n".join(items).format(**data))

Output using the same input as /u/NUNTIUMNECAVI:

3002 words
16571 letters
624 symbols
Top three most common words: ut, in, sed
Top three most common letters: e, i, u
Words only used once: torquent, himenaeos, aptent, litora, class, ad, sociosqu, inceptos, nostra, potenti, taciti, conubia
Letters not used in the document: y, x, k, z, w

I notice I got different results for the most common words... I'm not sure who
is correct here.

Also, I skipped the optional most-common-first-word-in-paragraph.

share
Save
tim25314
2 points·4 years ago

Few comments:

words = [w.strip(punctuation) for w in text.split()]

I liked that a lot, it was a lot cleaner than how I generated the words.

I also liked

"unused_letters": ", ".join(set(ascii_lowercase) - set(letters))

I don't think I would have thought of that.

share
Save
Coder_d00d
1 32 points·4 years ago·edited 4 years ago

Objective C (using Apple's Foundation Framework) -- All Bonuses Done!

Not seeing many compiled languages :/ I can see where scripted languages can
produce solutions with brevity.

Note: On the top 3 for words or letters I was noticing lots of ties in my test
cases. So my top 3 letter/words are based on the count value and not just the
top 3 on my sorted list. So I show the letters and words with the count values
to show that ties are possible.

//
//  main.m
//  Challenge 125 - Word Analytics

#import <Foundation/Foundation.h>

#define VALID_ARGUMENT_SIZE     2
#define ARGUMENT_FILE           1

#define ERROR_USAGE             1
#define ERROR_FILE_OPEN_FAILED  2


// Define my own versions of the ctype.h functions that fit the challenge

// NOTE: Values are based on ASCII Table - Consult an ASCII table to see my blocks of characters used
// to define whitespace vs symbols. Letters are ignored and neither whitespace of symbols.


bool isLetter(char c) {
    if ( (c >= 'A' && c <= 'Z') ||
        (c >= 'a' && c <= 'z') )
        return true;
    return false;
}

bool needsCaps(char c) {
    if (c >= 'a' && c <= 'z')
        return true;
    return false;
}

char OMG_CAPS_LOCK_IT(char c)
{
    if (c >= 'a' && c <= 'z')
        return (c - 32);
    return c;
}

bool isWhiteSpace(char c) {
    if (c <= 32)
        return true;
    return false;
}

bool isSymbol(char c) {
    if ( (c >= 33 && c <= 47) ||
        (c >= 58 && c <= 64) ||
        (c >= 91 && c <= 96) ||
        (c >= 123 && c <= 126))
        return true;
    return false;
}

bool atNewParagraph(NSString *data, NSUInteger index) {
    if ([data length] < 2 || index == 0)
        return false;
    if ([data characterAtIndex: index] == '\n' &&
        [data characterAtIndex: index-1] == '\n')
        return true;
    return false;
}

// Helper Functions

void incrementDictionary(NSMutableDictionary *dict, NSString *key) {
    NSNumber *value = [dict objectForKey: key];
    int count;

    if (!value) {
        value = [[NSNumber alloc] initWithInt: 1];
        [dict setObject: value forKey: key];
    } else {
        count = [value intValue];
        count++;
        [dict removeObjectForKey: key];
        value = [[NSNumber alloc] initWithInt: count];
        [dict setObject: value forKey: key];
    }
}

void showMeTop(int max, NSMutableDictionary *dict) {

    int value;
    NSArray *sorted = [dict keysSortedByValueUsingComparator:
                       ^(id one, id two) {
                           return [one compare: two];
                       }];
    int count = 0;

    for (int i = (int) [sorted count] - 1; i >= 0; i--) {
        value = [[dict objectForKey: [sorted objectAtIndex: i]] intValue];
        printf("(%d)%s ", value, [[sorted objectAtIndex: i] UTF8String]);
        if (i > 0 && value != [[dict objectForKey: [sorted objectAtIndex: (i-1)]] intValue])
            count++;
        if (count == max) break;
    }
    printf("\n");
}

void showMeOnce(NSMutableDictionary *dict) {

    bool firstDone = false;
    NSArray *sorted = [dict keysSortedByValueUsingComparator:
                       ^(id one, id two) {
                           return [one compare: two];
                       }];

    for (int i = 0; i < [sorted count]; i++) {
        if ([[dict objectForKey: [sorted objectAtIndex:i]] intValue] == 1) {
            if (firstDone) printf(",");
            printf("%s", [[sorted objectAtIndex: i] UTF8String]);
            if (!firstDone) firstDone = true;
        }
    }
    printf("\n");
}

void showMeLettersMissing(NSMutableDictionary *dict) {
    char c;
    NSNumber *count;
    bool firstDone = false;

    for (c = 'A'; c <= 'Z'; c++) {
        count = [dict objectForKey: [[NSString alloc] initWithFormat: @"%c", c]];
        if (!count) {
            if (firstDone) printf(",");
            printf("%c", c);
            if (!firstDone) firstDone = true;
        }
    }
}


int main(int argc, const char * argv[])
{

    @autoreleasepool {

        NSString        *fileName;
        NSString        *key;
        NSMutableString *fileData;
        NSError         *error;
        NSUInteger      index;
        NSUInteger      beginOfWord;
        NSUInteger      numberOfWords = 0;
        NSUInteger      numberOfLetters = 0;
        NSUInteger      numberOfSymbols = 0;
        int             newLineCount = 0;
        bool            readWord = false;
        bool            firstParagraphWord = false;
        bool            seenFirstParagraph = false;
        char            c;

        NSMutableDictionary *commonWords = [[NSMutableDictionary alloc] initWithCapacity: 0];
        NSMutableDictionary *commonLetters = [[NSMutableDictionary alloc] initWithCapacity: 0];
        NSMutableDictionary *commonFirstParagraphWord = [[NSMutableDictionary alloc] initWithCapacity: 0];

        if (argc < VALID_ARGUMENT_SIZE) {
            printf("Error! usage: (file\n");
            return ERROR_USAGE;
        }
        fileName = [[NSString alloc] initWithCString: argv[ARGUMENT_FILE] encoding: NSASCIIStringEncoding];
        fileData = [NSMutableString stringWithContentsOfFile: fileName
                                                    encoding: NSUTF8StringEncoding
                                                       error: &error];
        if (error) {
            printf("Error could not open file to read\n");
            return ERROR_FILE_OPEN_FAILED;
        }
        index = 0;
        c = (char) [fileData characterAtIndex: index++];
        while (index < [fileData length]) {

            if (isWhiteSpace(c)) {
                do {
                    if (c == '\n')
                        newLineCount++;
                    c = (char) [fileData characterAtIndex: index++];
                } while (isWhiteSpace(c) && index < [fileData length]);

            } else if (isLetter(c)) {
                do {
                    if (newLineCount >= 2 || !seenFirstParagraph)
                    {
                        firstParagraphWord = true;
                        newLineCount = 0;
                        if (!seenFirstParagraph) seenFirstParagraph = true;
                    }
                    if (needsCaps(c)) {
                        c = OMG_CAPS_LOCK_IT(c);
                        key = [[NSString alloc] initWithFormat: @"%c", c];
                        [fileData replaceCharactersInRange: NSMakeRange(((int) index  - 1), 1)
                                                withString: key];
                    } else
                        key = [[NSString alloc] initWithFormat: @"%c", c];
                    incrementDictionary(commonLetters, key);
                    numberOfLetters++;
                    if (!readWord) {
                        beginOfWord = index - 1;
                        readWord = true;
                    }
                    c = (char) [fileData characterAtIndex: index++];
                } while (isLetter(c) && index < [fileData length] );
                if (readWord) {
                    numberOfWords++;
                    readWord = false;
                    key = [fileData substringWithRange: NSMakeRange(beginOfWord, (index - beginOfWord - 1))];
                    incrementDictionary(commonWords, key);
                    if (firstParagraphWord) {
                        incrementDictionary(commonFirstParagraphWord, key);
                        firstParagraphWord = false;
                    }
                }
            } else if (isSymbol (c)) {
                do {
                    numberOfSymbols++;
                    c = (char) [fileData characterAtIndex: index++];
                } while (isSymbol(c) && index < [fileData length]);
            } else
                c = (char) [fileData characterAtIndex: index++];
        } // main while loop


        printf("Processing File: %s\n", argv[ARGUMENT_FILE]);
        printf("==============================================\n");
        printf("%d words\n", (int) numberOfWords);
        printf("%d letters\n", (int) numberOfLetters);
        printf("%d symbols\n", (int) numberOfSymbols);

        printf("Top 3 most common words: ");
        showMeTop(3,commonWords);

        printf("Top 3 most common letters: ");
        showMeTop(3,commonLetters);

        printf("Most common first word of a Paragraph: ");
        showMeTop(1, commonFirstParagraphWord);

        printf("Words used only once: ");
        showMeOnce(commonWords);

        printf("Letters not used in the document: ");
        showMeLettersMissing(commonLetters);

    } // autorelasepool
    return 0;
}

Output -- using NUNTIUMNECAVI's input [Pastebin] (http://pastebin.com/fHPpf2xN)

My results are similar to others. Keep in mind my top 3s show ties based on
count values.

Processing File: /tmp/test.txt
==============================================
3002 words
16571 letters
624 symbols
Top 3 most common words: (56)UT (53)IN (53)SED (51)AMET (51)SIT
Top 3 most common letters: (1921)E (1703)I (1524)U
Most common first word of a Paragraph: (3)VESTIBULUM (3)NUNC
Words used only once: NOSTRA,LITORA,HIMENAEOS,POTENTI,CLASS,AD,SOCIOSQU,INCEPTOS,CONUBIA,TACITI,APTENT,TORQUENT
Letters not used in the document: K,W,X,Y,Z

share
Save
GhostNULL
2 points·4 years ago

Good to see a compiled language :) I was working on one too but that was really
late at night so I haven't finished yet :/

share
Save
ouimet51
1 point·4 years ago

This is the first thing I have ever actually coded on my own. I would love some
feed back, I only did the challages that weren't "Optional Bonus". I know this
code it probably messy and inefficient so tips would be great.

import re
import collections

f = open("/Users/ouimet51/python/nyr_wiki.txt", mode="r")
data = f.read()
word_list = data.split(" ")

print word_list

def word_counter():
    print "%s Words" % len(word_list)

word_counter()

def letter_counter():
    print "%s Letters" % len(data)

letter_counter()

def symbol_counter():
    oddchar = re.findall(r'([^\w\s]+)', data)
    print "%s Symbols" % len(oddchar)

symbol_counter()

counter = collections.Counter(word_list)
print(counter.most_common(3))

share
Save
Tychonaut
2 points·4 years ago

I have to admit, I don't know Python at all, but your answer seemed so short I
looked at it to try to see if I could figure out what is going on.

I think you aren't taking "edge cases" into consideration. For example, if you
just split the file by spaces, then something like this

    "Check the invitation ( attached )."

Would count that bracket as a word. It would also count

    "My number is 555 1234."

as 5 words. So I think that for everything you have in your word list, you need
to do further testing on it to make sure it isn't all numbers or a special
character. Only include it as a "real word" if it has at least one letter in
it.

share
Save
475c
1 point·4 years ago·edited 4 years ago

Joined so I can do these and get better. I have some work to do. :) I did all
of them except the paragraph one and I'm not exactly sure why I had to error
check at the very end of the code but it appears to work... it's Python 2.7

    from sys import argv
    import string
    from collections import Counter

    fil = open(argv[1], "r")
    words = fil.read()
    realwords = []
    for i in words:
            if i == "\n":
                realwords.append(" ")
            else:
                realwords.append(i.rstrip(string.punctuation))
    newpunc = string.punctuation + "\n"
    realwords = ''.join(realwords).split(" ")
    letters = [i for i in ''.join(realwords).split(" ") if i not in newpunc]
    punctuation = [i for i in ''.join([i for i in words]) if i in newpunc[0:-1]]
    letters = list(letters[0])

    while 1:
        try:
            realwords.remove("")
        except ValueError:
            break

    word_count = Counter(realwords)
    letter_count = Counter(letters)

    print("Letters not used >> " + ' '.join([i for i in string.ascii_lowercase
                    if i not in ''.join(letters).lower()]))

    print("Number of words >> " + str(len(realwords)))
    print("Number of letters >> " + str(len(letters)))
    print("Number of symbols >> " + str(len(punctuation)))

    print("Most common words >> " + word_count.most_common(3)[0][0] + ":" +
          str(word_count.most_common(3)[0][1]) + ", " + word_count.most_common(3)[1][0] + ":" +
          str(word_count.most_common(3)[1][1]) + ", " + word_count.most_common(3)[2][0] + ":" +
          str(word_count.most_common(3)[2][1]))

    print("Most common letters >> " + letter_count.most_common(3)[0][0] + ":" +
          str(letter_count.most_common(3)[0][1]) + ", " + letter_count.most_common(3)[1][0] +
          ":" + str(letter_count.most_common(3)[1][1]) + ", " + letter_count.most_common(3)[2][0] +
          ":" + str(letter_count.most_common(3)[2][1]))

    print("--- Words used only once ---")
    for i in range(0, len(realwords)-1):
        try:
            if word_count.most_common(len(realwords))[i][1] == 1:
                print(word_count.most_common(len(realwords))[i][0])
        except IndexError:
            break

Gives this output:

Letters not used >> k w x y z
Number of words >> 3002
Number of letters >> 16571
Number of symbols >> 624
Most common words >> amet:51, sit:51, et:48
Most common letters >> e:1909, i:1679, u:1513
--- Words used only once ---
litora
torquent
nostra
himenaeos
sociosqu
Class
aptent
inceptos
conubia
taciti
ad
potenti

share
Save
TheCiderman
2 points·4 years ago

How very strange. I get all the same results as you, except for the most common
words. My top 3 are ut:56, in:53, sed:53 Have done a manual check and ut is in
there 56 times. I am guessing that you are not doing the case insensitive
thing? but it is only a guess as I don't know Python.

share
Save
K3nobi
1 point·4 years ago

Solution in Ruby:

https://gist.github.com/K5nobi/5588393

share
Save
tim25314
1 point·4 years ago

Python solution with bonus:

import sys, string, collections

fileStr = sys.stdin.read()
words = [''.join(letter for letter in word if letter in string.letters) for word in fileStr.split()]
letters = ''.join(words).lower()
paragraphs = fileStr.split("\n\n")
firstWordOfParagraph = [paragraph.split()[0].lower() for paragraph in paragraphs]

numWords = len(words)
numLetters = len(letters)
numSymbols = len([x for x in fileStr if x not in string.letters and x not in (" ", "\n")])

wordCount = collections.Counter(word.lower() for word in words)
mostCommonWords = ['"{0}"'.format(x[0]) for x in wordCount.most_common(3)]

letterCount = collections.Counter(letters)
mostCommonLetters = ["'{0}'".format(x[0]) for x in letterCount.most_common(3)]

mostCommonFirstWord = collections.Counter(firstWordOfParagraph).most_common(1)[0][0]
wordsUsedOnce = ['"{0}"'.format(x[0]) for x in wordCount.iteritems() if x[1] == 1]
lettersNotUsed = ["'{0}'".format(x) for x in string.lowercase if x not in letters]

print "{0} words".format(numWords)
print "{0} letters".format(numLetters)
print "{0} symbols".format(numSymbols)
print "Top three most common words: {0}".format(', '.join(mostCommonWords))
print "Top three most common letters: {0}".format(', '.join(mostCommonLetters))
print "{0} is the most common first word of all paragraphs".format(mostCommonFirstWord)
print "Words used only once: {0}".format(', '.join(wordsUsedOnce))
print "Letters not used in the document: {0}".format(', '.join(lettersNotUsed))

share
Save
gopheringaround
1 point·4 years ago·edited 4 years ago

Full solution in golang. Probably quite inefficient, just something I hacked
together quickly.

package main

import (
    "fmt"
    "os"
    "sort"
    "strings"
    "regexp"
    "io/ioutil"
)

var (
    justLetters = regexp.MustCompile(`\W+`)
    justSpecial = regexp.MustCompile(`[a-zA-Z0-9 \r\n\t]`)
    justWords = regexp.MustCompile(`[^a-zA-Z ]`)
)

type SortedMap struct {m map[string]int; s []string}
func (s *SortedMap) Len() int {return len(s.m)}
func (s *SortedMap) Less(i, j int) bool {return s.m[s.s[i]] > s.m[s.s[j]]}
func (s *SortedMap) Swap(i, j int) {s.s[i], s.s[j] = s.s[j], s.s[i]}

type Text struct {
    Body string
    Letters string
    Symbols string
    Words []string
}

func newText(s string) *Text {
    return &Text{s, justLetters.ReplaceAllString(s, ""), justSpecial.ReplaceAllString(s, ""), strings.Fields(justWords.ReplaceAllString(s, ""))}
}

func(t Text) CountWords() int {
    return len(t.Words)
}

func(t Text) CountLetters() int {
    return len(t.Letters)
}

func (t Text) CountSymbols() int {
    return len(t.Symbols)
}

func (t Text) GetWordStats() ([]string, []string) {
    sm, usedonce := initializer(t.Words), make([]string, 0)
    sort.Sort(sm)
    for key, val := range sm.m {if val == 1 {usedonce = append(usedonce, key)}}
    if len(sm.s) > 2 {return sm.s[:3], usedonce}
    return sm.s[:len(sm.s)], usedonce
}

func (t Text) GetMostCommonLetters() []string {
    sm := initializer(strings.Split(t.Letters, ""))
    sort.Sort(sm)
    if len(sm.s) > 2 {return sm.s[:3]}
    return sm.s[:len(sm.s)]
}

func (t Text) GetMostCommonFirstWord() string {
    paragraphs := strings.Split(t.Body, "\n\n")
    words := make([]string, len(paragraphs))
    for i, paragraph := range paragraphs {words[i] = strings.Fields(paragraph)[0]}
    sm := initializer(words)
    if len(sm.s) > 0 {return sm.s[0]}
    return ""
}

func (t Text) GetNotUsed() []string {
    letters, notused := strings.ToLower(t.Letters), make([]string, 0)
    table := make(map[int]struct{}, 26)
    for _, rune := range letters {
        table[int(rune)] = struct{}{}
    }
    for i := 97; i < 123; i ++ {if _, ok := table[i]; ok == false {notused = append(notused, string(rune(i)))}}
    return notused
}

//Helpers
func initializer(separated []string) *SortedMap {
    _map := make(map[string]int)
    for _, word := range separated {
        word = strings.ToLower(word)
        if val, ok := _map[word]; ok {
            _map[word] = val + 1
            continue
        }
        _map[word] = 1
    }
    _slice := make([]string, len(_map))
    i := 0; for key, _ := range _map {_slice[i] = key; i++}
    return &SortedMap{_map, _slice}
}

 func main(){
    args := os.Args
    path := args[len(args) - 1]
    b, err := ioutil.ReadFile(path); if err != nil {panic(err)}
    text := newText(string(b))
    topThree, usedOnce := text.GetWordStats()
    fmt.Printf("%d words\n", text.CountWords())
    fmt.Printf("%d letters\n", text.CountLetters())
    fmt.Printf("%d symbolds\n", text.CountSymbols())
    fmt.Printf("Top three most common words: %q\n", topThree)
    fmt.Printf("Top three most common letters: %q\n", text.GetMostCommonLetters())
    fmt.Printf("%q is the most common first word of all paragraphs\n", text.GetMostCommonFirstWord())
    fmt.Printf("Words only used once: %q\n", usedOnce)
    fmt.Printf("Letters not used in the document:%q\n", text.GetNotUsed())
 }

share
Save
altanic
1 point·4 years ago

first submission! Great subredit... well, here's a late attempt in C#. This is
a mongrel of how I did this in C way back in the day combined with what I know
of C#. I created my own type for the string,int structure but I see somebody
else used a Dictionary collection which I like better. I attempted all the
bonuses but the paragraph one. I figure I'd just keep track of consecutive
newlines & tag the next word, adding it to another list... but I got lazy. :)

   class Program {
          static void Main(string[] args) {
                 if (args.Count() == 0 || (!File.Exists(args[0]))) {
                        Console.WriteLine("File not found");
                        return;
                 }
                 StreamReader sr = new StreamReader(args[0]);

                 StringBuilder sb = new StringBuilder();

                 var words = new List<Token>();
                 var chars = new List<Token>();

                 char c;
                 int wordCount = 0, letterCount = 0, symbolCount = 0;

                 while (sr.Peek() != -1) {
                        c = (char)sr.Read();

                        if (Char.IsLetter(c)) {
                           letterCount++;
                           addToken(chars, c.ToString());
                           sb.Append(c);
                        }
                        else {
                           if (!Char.IsWhiteSpace(c))
                                  symbolCount++;
                           continue;
                        }

                        if(!Char.IsLetter((char)sr.Peek())) {
                           wordCount++;
                           addToken(words, sb.ToString());
                           sb.Length = 0;
                        }
                 }
                 sr.Close();

                 Console.WriteLine("{0} words", wordCount);
                 Console.WriteLine("{0} letters", letterCount);
                 Console.WriteLine("{0} symbols", symbolCount);
                 Console.WriteLine("Top three most common words: {0}, {1}, {2}", words.OrderByDescending(n => n.Count).Take(3).ToArray());
                 Console.WriteLine("Top three most common letters: {0}, {1}, {2}", chars.OrderByDescending(n => n.Count).Take(3).ToArray());
                 Console.WriteLine("Number of words only used once: {0}", words.Where(n => n.Count == 1).Count());

                 sb.Length=0;
                 for (int i = 97; i < 123; i++)
                        if (!chars.Select(n => n.Value).ToArray().Contains(((char)i).ToString()))
                           sb.Append((char)i + @", ");

                 sb.Length = sb.Length - 2;
                 Console.Write(@"Letters not used in the document: {0}", sb.ToString());
          }

          static void addToken(List<Token> words, string t) {
                 var tokens = words.Where(tk => tk.Value.Equals(t, StringComparison.OrdinalIgnoreCase));
                 if (tokens.Count() == 0)
                        words.Add(new Token(t.ToLower()));
                 else
                        tokens.Single().Count += 1;
          }
   }

   public class Token {
          public string Value { get; set; }
          public int Count { get; set; }

          public Token(string s) {
                 this.Value = s;
                 this.Count = 1;
          }

          public override string ToString() {
                 return this.Value;
          }
   }

here's the output:

3002 words
16571 letters
624 symbols
Top three most common words: ut, in, sed
Top three most common letters: e, i, u
Number of words only used once: 12
Letters not used in the document: k, w, x, y, z

share
Save
poorbowelcontrol
1 point·4 years ago·edited 4 years ago

My attempt in ruby

module Anal def self.start

s = File.read("./text")
ts = s.tr('a-zA-Z0-9 ','').length
a = s.downcase.tr('^a-z ','').split(' ')


words = Hash.new()
tw = 0
tl = 0
a.each do |w|
  if words.has_key?(w)
    words[w] = words[w] + 1
  else
    words[w] = 1
  end
  tw = tw + 1
  tl = tl + w.length
end
puts "Total Words: #{tw}"
puts "Total letters: #{tl}"
puts "Total symbols: #{ts}"

top = words.sort{|k,v| v[1]<=>k[1]}
puts "Top three most common words: #{top[0][0]} #{top[1][0]} #{top[2][0]}"

letters = s.upcase.tr('^A-Z','').split('')
distinct_letters = Hash.new()
letters.each do |l|
  if distinct_letters.has_key?(l)
    distinct_letters[l] = distinct_letters[l] + 1
  else
    distinct_letters[l] = 1
  end
end

top_letters = distinct_letters.sort{|k,v| v[1]<=>k[1]}

puts "Most Common letters #{top_letters[0][0]} #{top_letters[1][0]} #{top_letters[2][0]}"

end end

share
Save
odinsride
1 point·4 years ago·edited 4 years ago

Took a stab at it with PL/SQL - got to use some Oracle features I don't use on
a regular basis, hooray!

CREATE OR REPLACE DIRECTORY data_dir AS '/datafiles';

CREATE OR REPLACE TYPE t_list IS TABLE OF VARCHAR2(255);

DECLARE

  c_input_dname     CONSTANT VARCHAR2(30)          := 'DATA_DIR';
  c_input_fname     CONSTANT VARCHAR2(30)          := 'input.txt';

  l_word_count      NUMBER                         := 0;
  l_letter_count    NUMBER                         := 0;
  l_symbol_count    NUMBER                         := 0;
  l_top_words       VARCHAR2(255);
  l_top_letters     VARCHAR2(255);

  t_words           t_list                         := t_list(0);
  t_letters         t_list                         := t_list(0);

  cur_rc            SYS_REFCURSOR;

  PROCEDURE print
    (p_string_i     IN VARCHAR2)
  IS
  BEGIN
    dbms_output.put_line(p_string_i);
  END print;

  -- Process contents of input file
  PROCEDURE process_input
    (p_dname        IN VARCHAR2
    ,p_fname        IN VARCHAR2)
  IS

    c_input_openmode  CONSTANT VARCHAR2(2)           := 'r';

    l_handler         utl_file.file_type;
    l_line            VARCHAR2(4000);

    l_word_search     VARCHAR2(50)                   := '[(^|\s)a-zA-Z(\s|$)]+';
    l_symbol_search   VARCHAR2(50)                   := '[^a-zA-Z]';

  BEGIN

    l_handler := utl_file.fopen(p_dname, p_fname, c_input_openmode);

    IF utl_file.is_open(l_handler) THEN
      LOOP
        BEGIN

          utl_file.get_line(l_handler, l_line);

          -- Count Symbols
          l_symbol_count := l_symbol_count + regexp_count(l_line, l_symbol_search);

          -- Get words
          FOR i IN 1 .. regexp_count(l_line, l_word_search) LOOP

            t_words.extend;
            t_words(t_words.count)   := regexp_substr(l_line, l_word_search, 1, i);
            -- Add word to nested table

            -- Get letters
            FOR j IN 1 .. LENGTH(t_words(t_words.count)) LOOP

              t_letters.extend;
              t_letters(t_letters.count)  := SUBSTR(t_words(t_words.count), j, 1);

            END LOOP;

          END LOOP;

        EXCEPTION
          WHEN NO_DATA_FOUND THEN
            EXIT;
        END;
      END LOOP;
    END IF;

    utl_file.fclose(l_handler);

  END process_input;

  -- Determine top words/letters
  FUNCTION top_values
    (p_cursor       IN  SYS_REFCURSOR)
  RETURN VARCHAR2
  IS

    l_value         VARCHAR2(255);
    l_value_string  VARCHAR2(255);

  BEGIN

    LOOP
      FETCH p_cursor INTO l_value;
        EXIT WHEN p_cursor%NOTFOUND;

      IF l_value_string IS NULL THEN
        l_value_string := l_value;
      ELSE
        l_value_string := l_value_string || ', ' || l_value;
      END IF;

    END LOOP;
    print(l_value_string);
    RETURN (l_value_string);

  END top_values;

  -- Print output
  PROCEDURE print_output
  IS
  BEGIN

    print(l_word_count   || ' words');
    print(l_letter_count || ' letters');
    print(l_symbol_count || ' symbols');
    print('Top three most common words: ' || l_top_words);
    print('Top three most common letters: ' || l_top_letters);

  END print_output;

BEGIN

  process_input(c_input_dname, c_input_fname);

  -- Get word counts
  l_word_count    := t_words.count;
  l_letter_count  := t_letters.count;

  -- Get Top Words
  OPEN cur_rc FOR SELECT '"' || INITCAP(column_value) || '"' column_value
                    FROM (SELECT column_value
                            FROM TABLE(t_words)
                           GROUP BY column_value
                           ORDER BY count(*) DESC)
                   WHERE ROWNUM <= 3;

  l_top_words := top_values(cur_rc);

  CLOSE cur_rc;

  -- Get Top Letters
  OPEN cur_rc FOR SELECT '''' || UPPER(column_value) || '''' column_value
                    FROM (SELECT column_value
                            FROM TABLE(t_letters)
                           GROUP BY column_value
                           ORDER BY count(*) DESC)
                   WHERE ROWNUM <= 3;

  l_top_letters := top_values(cur_rc);

  CLOSE cur_rc;

  -- Print results
  print_output;

END word_analytics;
/

Sample output using 30 paragraph input:

3003 words
16572 letters
3712 symbols
Top three most common words: "Amet", "Sit", "Et"
Top three most common letters: 'E', 'I', 'U'

share
Save
jh1997sa
1 point·4 years ago

Here's my attempt with Java, I haven't done 4 or 5 because it seems that you'd
use a HashMap and the book I'm reading hasn't covered those yet.

package dailyprogrammer;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;

public class Challenge125 {
        public static void main(String[] args) throws IOException {
                Path file = Paths.get("file.txt");

                BufferedReader reader = new BufferedReader(new InputStreamReader(Files.newInputStream(file)));

                String line = null;
                StringBuffer str = new StringBuffer();
                while ((line = reader.readLine()) != null) {
                        str.append(line);
                }

                long wordCount = getWordCount(str.toString());
                long charCount = getCharCount(str.toString());
                long symbolCount = getSymbolCount(str.toString());

                System.out.printf("%d words\n"
                                                + "%d characters\n"
                                                + "%d symbols\n", wordCount, charCount, symbolCount);
        }

        public static long getWordCount(String str) {
                String[] words = str.split(" ");

                return words.length;
        }

        public static long getCharCount(String str) {
                String[] words = str.split(" ");

                long count = 0;
                for (String w : words) {
                        for (char c : w.toCharArray()) {
                                ++count;
                        }
                }

                return count;
        }

        public static long getSymbolCount(String str) {
                String[] words = str.split(" ");

                long count = 0;
                for (String w : words) {
                        for (char c : w.toCharArray()) {
                                if (!Character.isLetterOrDigit(c) && !Character.isWhitespace(c)) {
                                        ++count;
                                }
                        }
                }

                return count;
        }
}

Input: http://www.gutenberg.org/cache/epub/10/pg10.txt

Output: 751113 words 3500510 characters 157405 symbols

share
Save
courtstreet
1 point·4 years ago·edited 4 years ago

Found this sub today and it seemed like an awesome way to learn a new language.
This is the first thing I have written in python. No error handling and some
duplication that I'm not happy with but I figured it was good enough for a
first go.

As an aside - I feel like I was fighting vim more than the problem itself. What
do you guys use to edit python files? I am definitely spoiled by visual studio
at work...

import sys
import string
import operator

def aggregate(dict, item):
    if item in dict:
        dict[item] += 1
    else:
        dict[item] = 1
    return

def getValueString(dict, num):
    output = ""
    first = True
    i = 0
    while i < len(dict) and i < num:
        if not first:
            output += ", "
        output += dict[i][0]
        i += 1
        first = False
    return output

scannedFile = open(sys.argv[1], "r")

charDict = {}
wordDict = {}
firstWordDict = {}
wordCount = 0
charCount = 0
symbolCount = 0

firstWord = True
currentWord = ""
for line in scannedFile:

    if line.strip() == "":
        firstWord = True;

    for char in line:
        if char in string.punctuation:
            symbolCount += 1
            if len(currentWord):
                wordCount += 1
                aggregate(wordDict, currentWord)
                if firstWord:
                    aggregate(firstWordDict, currentWord)
                    firstWord = False
            currentWord = ""
        elif char in string.letters:
            currentWord += char
            charCount += 1
            aggregate(charDict, char)
        elif char in string.whitespace:
            if len(currentWord):
                wordCount += 1
                aggregate(wordDict, currentWord)
                if firstWord:
                    aggregate(firstWordDict, currentWord)
                    firstWord = False
            currentWord = ""

if wordCount:
    print "number of words - ", wordCount
if charCount:
    print "number of letters - ", charCount
if symbolCount:
    print "number of symbols - ", symbolCount

sortedWords =  sorted(wordDict.iteritems(), key=operator.itemgetter(1), reverse=True)
sortedChars = sorted(charDict.iteritems(), key=operator.itemgetter(1), reverse=True)
sortedFirstWords = sorted(firstWordDict.iteritems(), key=operator.itemgetter(1), reverse=True)

if len(sortedWords):
    print "the top three most common words were - ", getValueString(sortedWords, 3)
if len(sortedChars):
    print "the top three most common letters were - ", getValueString(sortedChars, 3)
if len(sortedFirstWords):
   print "the top three most common first words were - ", getValueString(sortedFirstWords, 3)

scannedFile.close()

sample output:

python pd125.py lorem.txt
number of words -  1770
number of letters -  10094
number of symbols -  385
the top three most common words were -  et, aut, qui
the top three most common letters were -  e, i, u
the top three most common first words were -  Sed

edit: not sure why the formatting is getting screwed up... edit2: figured
spacing out

share
Save
thatusernameisalre
1 point·4 years ago

Ruby:

        #!/usr/bin/env ruby

        word_count = 0
        letter_count = 0
        symbol_count = 0
        word_tally = Hash.new(0)
        letter_tally = Hash.new(0)
        newline_flag = false


        def alpha?(c)
                c =~ /[[:alpha:]]/
        end

        def digit?(c)
                c =~ /[[:digit:]]/
        end


        ARGF.each_line do |line|
                line.downcase.split.each do |word|
                        word_count += 1
                        word_tally[word.capitalize] += 1

                        word.each_char do |char|
                                if alpha?(char)
                                        letter_count += 1
                                        letter_tally[char.capitalize] += 1
                                elsif !alpha?(char) and !digit?(char)
                                        symbol_count += 1
                                end
                        end
                end
        end

        # Le dump.

        if word_count > 0
                puts "#{word_count} words"
        end

        if letter_count > 0
                puts "#{letter_count} letters"
        end

        if symbol_count > 0
                puts "#{symbol_count} symbols"
        end

        if word_tally.size > 2
                print "Top three most common words: "

                word_tally.sort_by { |k, v| v }.reverse.each_with_index do |e, i|
                        print "\"#{e[0]}\""

                        if i < 2
                                print ", "
                        else
                                print "\n"
                                break
                        end
                end
        end

        if letter_tally.size > 2
                print "Top three most common letters: "

                letter_tally.sort_by { |k, v| v }.reverse.each_with_index do |e, i|
                        print "'#{e[0]}'"

                        if i < 2
                                print ", "
                        else
                                print "\n"
                                break
                        end
                end
        end

share
Save
Cazzar
1 point·4 years ago·edited 4 years ago

here is my own C# 4.0 LINQ

using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Text.RegularExpressions;

namespace DailyProgrammer125
{
    class Program
    {
        static void Main(string[] args)
        {
            if (args.Length != 1)
            {
                Console.WriteLine("{0} [path]", AppDomain.CurrentDomain.FriendlyName.Replace(".exe", ""));
                return;
            }

            var text = File.ReadAllText(args[0]);
            Console.WriteLine("{0} words", text.Split(new []{'\n', ' '}, StringSplitOptions.RemoveEmptyEntries).Length);
            Console.WriteLine("{0} letters", text.Count(char.IsLetter));
            var count = text.Replace("\n", "").Replace(" ", "").Where(char.IsLetterOrDigit).Count();
            Console.WriteLine("{0} symbols", text.Length - count);

            var words = new Dictionary<string, int>();
            foreach (var word in text.Split(' '))
            {
                if (words.ContainsKey(word.ToLower())) words[word.ToLower()]++;
                else words.Add(word.ToLower(), 1);
            }

            var items = from pair in words orderby pair.Value descending select pair;
            Console.WriteLine("Top 3 most common words: {0}", String.Join(", ", items.Take(3).Select(p => p.Key)));

            var chars = new Dictionary<char, int>();
            foreach (var c in text.ToLower().Where(char.IsLetter))
            {
                if (chars.ContainsKey(c)) chars[c]++;
                else chars.Add(c, 1);
            }

            var orderedChars = (from pair in chars orderby pair.Value descending select pair);
            Console.WriteLine("Top 3 most common characters: {0}", String.Join(", ", orderedChars.Take(3).Select(p => p.Key)));

            Console.WriteLine("Words only used once: {0}", String.Join(", ", items.Where((k, v) => v == 1).Select(k => k.Key)));

            var paragraphs = Regex.Split(text, "\n\n");
            words = new Dictionary<string, int>();
            foreach (var word in paragraphs.Select(paragraph => paragraph.Split(new []{' '}, StringSplitOptions.RemoveEmptyEntries)[0]))
            {
                if (words.ContainsKey(word.ToLower())) words[word.ToLower()] = words[word.ToLower()] + 1;
                else words.Add(word.ToLower(), 1);
            }

            items = from pair in words orderby pair.Value descending select pair;
            Console.WriteLine("{0} is the most common first word of all paragraphs", items.First().Key);

            var letters = new List<char> { 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z' };
            foreach (var c in text.Where(char.IsLetter).Where(letters.Contains))
                letters.Remove(c);

            Console.WriteLine("Letters not used in the document: {0}", String.Join(", ", letters));
        }
    }
}

And my output

2732 words
15186 letters
3365 symbols
Top 3 most common words: ut, sed, in
Top 3 most common characters: e, i, u
Words only used once: sed
cras is the most common first word of all paragraphs
Letters not used in the document: k, w, x, y, z

This could be much better, I only whipped it up in ~100 mins

Edit: added a proper help message for the case of not knowing what to do.

share
Save
iowa116
1 point·4 years ago

Here's my python solution:

from sys import argv
import string

script, filename = argv

txt_file = open(filename)
txt_file = txt_file.read()
txt_file = txt_file.lower()
word_list = txt_file.split(' ')

num_words = len(word_list)
initial = first_count = second_count = third_count = num_sym = num_letters = 0
letter_count = letter_one = letter_two = letter_three = 0
first_letter = second_letter = third_letter = third_word = second_word = ''

for word in word_list:
    for letter in word:
        if letter in string.punctuation:
            num_sym += 1
        letter_count = txt_file.count(letter)
        if letter_count > letter_one:
            first_letter = letter
            letter_one = letter_count
        elif letter_count > letter_two and letter_count < letter_one:
            second_letter = letter
            letter_two = letter_count
        elif letter_count > letter_three and letter_count < letter_one and letter_count < letter_two:
             third_letter = letter
             letter_three = letter_count
     num_letters += len(word)
     initial = word_list.count(word)
     if initial > first_count:
         first_count = initial
         first_word = word
     elif initial > second_count and initial <= first_count and word != first_word:
         second_count = initial
         second_word = word
     elif initial > third_count and initial <= first_count and initial <= second_count and word != first_word and word != second_word:
        third_count = initial
        third_word = word

 print "The number of words in the file " + filename + "is " + str(num_words)
 print "The number of letters: " + str(num_letters)
 print "The number of symbols " + str(num_sym)
 print "The three most common words: " + first_word + "(" + str(first_count) + ")"+ ", " + second_word + "(" + str(second_count) + ")" + ", and " + third_word + "(" + str(third_count) + ")"
 print "The three most common letters: " + first_letter + "(" + str(letter_one) + ")"+ ", " + second_letter + "(" + str(letter_two) + ")" + ", and " + third_letter + "(" + str(letter_three) + ")"

Input: Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

Output:

The number of words in the file text_file.txt is 69
The number of letters: 378
The number of symbols: 8
The three most common words: ut(3), in(3), and dolor(2)
The three most common letters: i(43), e(38), and t(32)

share
Save
tkaz
1 point·4 years ago·edited 4 years ago

Just found this subreddit so very late to the party but I figured might as well
post my python solution with one bonus

import re
from collections import Counter

def main():
        doc = open('doc.txt', 'r')
        text = doc.read()

        dbin = {'words': 0, 'letters': 0, 'symbols' : 0, 'uwords' : []}
        dbin['words'] += len(re.findall(r'\w+', text))
        dbin['letters'] += len(re.findall('[a-z]', text))
        dbin['symbols'] += len(re.findall('^[a-z][0-9]', text))

        wcount = Counter(re.findall(r'\w+', text))
        lcount = Counter(re.findall('[a-z]', text))

        for word, count in wcount.iteritems():
                if count == 1:
                        dbin['uwords'].append(word)

        print(str(dbin['words']) + ' words')
        print(str(dbin['letters']) + ' letters')
        print('Top three most common words: ' + str(wcount.most_common(3)))
        print('Top three most common letters: ' + str(lcount.most_common(3)))
        print('Words only used once: ' + str(dbin['uwords']))

if __name__ == '__main__':
  main()

The not very fancy output of a ten paragraph generated Lorum Ipsum File

980 words
5355 letters
Top three most common words: [('vel', 23), ('vitae', 20), ('non', 17)]
Top three most common letters: [('e', 616), ('i', 549), ('u', 490)]
Words only used once: ['litora', 'torquent', 'faucibus', 'facilisi', 'nostra', '
Lorem', 'porta', 'dis', 'sociosqu', 'mus', 'Class', 'himenaeos', 'aptent', 'ince
ptos', 'sociis', 'penatibus', 'ultrices', 'nascetur', 'ante', 'Cum', 'natoque',
'parturient', 'fringilla', 'conubia', 'Suspendisse', 'taciti', 'magnis', 'Nunc',
 'ad', 'Etiam', 'montes', 'convallis', 'Proin', 'ridiculus', 'Duis', 'potenti']

share
Save
BlackJNeutron
1 point·4 years ago

Here is my code? Please critique and tell me what I could do better

import java.io.; import java.util.; import java.util.regex.Matcher; import
java.util.regex.Pattern;

public class WordAnalyticsTwo {

public static Map<String, Integer> allWords, allLetters;
static Map<String, Integer> sortedWords, sortedLetters;
static int numOfWords= 0;
static int numOfLetters = 0;
static Stack q = new Stack();


public static void main(String[] args){

        try {

                //Read txt.txt
                BufferedReader reader = new BufferedReader(new FileReader("blog"));
                String line = null;

                while((line = reader.readLine()) != null){

                        //Stores all words in a HashMap
                        findWord(line);
                        //Stores all letters in a HashMap
                        findLetters(line);
                }
        } catch (FileNotFoundException e) {
                // TODO Auto-generated catch block
                e.printStackTrace();
        } catch (IOException e) {
                // TODO Auto-generated catch block
                e.printStackTrace();
        }

        //Sorts allWords and Letters by Value
        sortedWords = sortByComparator(allWords);
        sortedLetters = sortByComparator(allLetters);


        //Prints out all statitics
        System.out.println("Word Anaylitics Stats");
        System.out.println("Number of Words: " + numOfWords);
        System.out.println("Number of Letters: " + numOfLetters);
        System.out.print("Common Words: ");
        commonValues(sortedWords);
        System.out.print("Common Letters: ");
        commonValues(sortedLetters);

}


//Method: Stores all letters in a HashMap called allLetters
public static void findLetters(String letters){
        int initLetter = 1;
        String currLetter;
        allLetters = new HashMap<String, Integer>();
        Pattern p = Pattern.compile("[a-zA-Z]");
        Matcher m = p.matcher(letters);

        while(m.find()){
                currLetter = letters.substring(m.start(), m.end());
                if(!allLetters.containsKey(currLetter)){
                        allLetters.put(currLetter,initLetter);

                }else{
                        int value = allLetters.get(currLetter);
                        value++;
                        allLetters.put(currLetter, value);
                }
                numOfLetters++;


        }
}

//Method: Stores all words in a HashMap called all Words
public static void findWord(String word){
        int initWord = 1;
        String currWord;
        allWords = new HashMap<String, Integer>();
        Pattern p = Pattern.compile("[\\w']+");
        Matcher m = p.matcher(word);

        while(m.find()){

                currWord = word.substring(m.start(), m.end());
                if(!allWords.containsKey(currWord)){
                        allWords.put(currWord, initWord);

                }else{
                        int value = allWords.get(currWord);
                        value ++;
                        allWords.put(currWord, value);
                }
                numOfWords++;

        }

}
//Method: Prints Map values
public static void printMap(Map<String, Integer> map){
        for(Map.Entry entry : map.entrySet()){
                System.out.println("Key : " + entry.getKey() + " Value : "
                                + entry.getValue());
        }
}

//Method: Sorts HashMap
public static Map sortByComparator (Map unsortedMap){
        List list = new LinkedList(unsortedMap.entrySet());

        //sort list based on comparator
        Collections.sort(list, new Comparator(){
                public int compare(Object o1, Object o2){
                        return ((Comparable) ((Map.Entry) (o1)).getValue())
                    .compareTo(((Map.Entry) (o2)).getValue());
                }
        });

        // put sorted list into map again
        Map sortedMap = new LinkedHashMap();
        for(Iterator it = list.iterator(); it.hasNext();){
                Map.Entry entry = (Map.Entry) it.next();
                sortedMap.put(entry.getKey(), entry.getValue());
        }

        //Return hashMap
        return sortedMap;
}

public static void commonValues(Map<String, Integer> map){
        int max= 0; //Current Max Key values
        int curr = 0; //Current value

        //Loops through Map and finds the max value of map value
        //Stores Map value into a Stack
        for(Map.Entry entry : map.entrySet()){

                        curr = (Integer) entry.getValue();
                        if(max < curr){
                                //Stores Map value into a stack
                                q.add(entry.getKey());

                                //Maxs current value the new max value
                                max = curr;
                        }

        }

                //Prints out 3 most common key values
        if(q.size() >= 3){
                System.out.println(q.pop() + "," + q.pop() + "," + q.pop());
        }else{
                System.out.println("There are less than three words in the Document");
        }
}

}

share
Save
Community Details
r/dailyprogrammer

141k

Subscribers

87

Online

**Welcome to r/DailyProgrammer!** First time visitors of Daily Programmer
please [Read the Wiki] (http://www.reddit.com/r/dailyprogrammer/wiki/index) to
learn everything about this subreddit. 3 Programming Challenges a week!

SubscribeCreate Post
aboutcareerspress
advertisebloghelp
the reddit appreddit goldreddit gifts
content policy| privacy policy
user agreement| mod policy
© 2018 Reddit, Inc. All rights reserved
back to top
